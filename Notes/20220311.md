# 20220314学习笔记

***

# 刷题

***

# 八股

## os
>
> * [进程调度算法](#进程调度算法)
> * [进程调度时机](#进程调度时机)
> * [僵尸进程和孤儿进程](#僵尸进程和孤儿进程)
> * [进程状态转移](#进程状态转移)
> * [进程间共享和私有资源](#进程间共享和私有资源)
> * [线程](#线程)
> * [协程](#协程)
> * [线程间同步及系统调用](#线程间同步及系统调用)
> * [线程间共享和私有资源](#线程间共享和私有资源)
> * [进程与线程的区别](#进程与线程的区别)
> * [用户态和内核态](#用户态和内核态)
> * [什么是虚拟内存](#什么是虚拟内存)
> * [缺页中断](#缺页中断)
> * [虚拟内存置换算法](#虚拟内存置换算法)
> * [虚拟内存页表寻址](#虚拟内存页表寻址)
> * [说一下LINUX系统中的锁](#说一下LINUX系统中的锁)
> * [自旋锁发生死锁](#自旋锁发生死锁)
> * [死锁产生的条件](#死锁产生的条件)
> * [如何避免死锁](#如何避免死锁)
> * [死锁检测和死锁恢复](#死锁检测和死锁恢复)
> * [信号处理机制](#信号处理机制)
> * [哪两个信号不能忽略](#哪两个信号不能忽略)
> * [原子操作和锁机制](#原子操作和锁机制)

## 进程调度算法

### 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

* 先来先服务 first-come first-serverd（FCFS）
>
> * 非抢占式的调度算法，按照请求的顺序进行调度。
> * 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

* 短作业优先 shortest job first（SJF）
>
> * 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
> * 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

* 最短剩余时间优先 shortest remaining time next（SRTN）
>
> * 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。
> * 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

### 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

* 时间片轮转
>
> * 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
> * 当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

* 优先级调度
>
> * 为每个进程分配一个优先级，按优先级进行调度。
> * 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

* 多级反馈队列
>
> * 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
> * 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
> * 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。
> * 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

### 实时系统

* 实时系统要求一个请求在一个确定时间内得到响应。
* 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 进程调度时机
>
> * 进程状态转换的时刻：进程终止、进程睡眠；
> * 当前进程的时间片用完时（current->counter=0）；
> * 设备驱动程序
> * 进程从中断、异常及系统调用返回到用户态时；

## 僵尸进程和孤儿进程

* 当父进程先结束，子进程此时就会变成孤儿进程，孤儿进程会自动向上被init进程收养，init进程完成对状态收集工作。而且这种过继的方式也是守护进程能够实现的因素。
* 如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，回收进程资源，那么子进程描述符就会一直保存在系统中，这种进程称为僵尸进程。
  * 僵尸进程是每个子进程退出时必然经历的过程
  * 僵尸进程的危害
    * 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等）。直到父进程通过wait / waitpid来取时才释放.
    * 如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。  
  * 如何消除僵尸进程
    * kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管
    * 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。

## 进程状态转移

* 就绪状态（ready）：等待被调度
* 运行状态（running）
* 阻塞状态（waiting）：等待资源
>
> * 就绪状态的进程通过调度算法从而获得 CPU  时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
> * 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

## 进程间共享和私有资源

* 私有：地址空间、堆、全局变量、栈、寄存器（0-3G的用户空间）
* 共享：3-4G的内核空间

## 线程

线程是CPU调度的基本单位

## [协程](https://blog.csdn.net/pinganting/article/details/53750142)

[协程学习笔记](https://blog.csdn.net/somezz/article/details/81265198)

### 协程概述

* 协程是轻量级线程，拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。
* 协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。

### 协程和线程的区别

* 协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
* 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

### 应用场景

* I/O 密集型任务。

> * 这一点与多线程有些类似，但协程调用是在一个线程内进行的，是单线程，切换的开销小，因此效率上略高于多线程。
> * 当程序在执行 I/O 时操作时，CPU 是空闲的，此时可以充分利用 CPU 的时间片来处理其他任务。在单线程中，一个函数调用，一般是从函数的第一行代码开始执行，结束于 return 语句、异常或者函数执行（也可以认为是隐式地返回了 None ）。
> * 有了协程，我们在函数的执行过程中，如果遇到了耗时的 I/O 操作，函数可以临时让出控制权，让 CPU 执行其他函数，等 I/O 操作执行完毕以后再收回控制权。

## [线程间同步及系统调用](https://www.cnblogs.com/alinh/p/6905221.html)

### 信号量

信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：
>
> * P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。
> * V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。

* 系统调用
  * sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。
  * sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。

### 互斥量

互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区      时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。

* 系统调用
  * pthread_mutex_init:初始化互斥锁
  * pthread_mutex_destroy：销毁互斥锁
  * pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。
  * pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。

### 条件变量

条件变量，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。

* 系统调用
  * pthread_cond_init:初始化条件变量
  * pthread_cond_destroy：销毁条件变量
  * pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。
  * pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。

## [线程间共享和私有资源](https://www.cnblogs.com/Lxk0825/p/9559070.html)

* 私有：**线程栈，寄存器，程序寄存器**，线程ID，错误返回码，信号屏蔽字，调度优先级
* 共享：文件描述符表，堆，地址空间，全局变量，静态变量，进程代码段，进程的当前目录和进程用户ID与进程组ID

## 进程与线程的区别
>
> * 进程是cpu资源分配的最小单位，线程是cpu调度的最小单位。
> * 进程有独立的系统资源或地址空间，而同一进程内的线程共享进程的大部分系统资源,包括堆、代码段、数据段，每个线程只拥有一些在运行中必不可少的私有属性，比如线程Id,栈、寄存器、程序计数器PC(或者说IP)。
> * 一个进程崩溃，不会对其他进程产生影响；而一个线程崩溃，会让同一进程内的其他线程也宕掉。
> * 进程在创建、销毁时开销比较大，而线程比较小。进程创建的时候需要分配虚拟地址空间等系统资源，而销毁的的时候需要释放系统资源；线程只需要创建栈，栈指针，程序计数器，通用目的寄存器和条件码等，不需要创建独立的虚拟地址空间。
> * 进程切换开销比较打，线程比较小。进程切换需要分两步：切换页目录、刷新TLB以使用新的地址空间；切换内核栈和硬件上下文（寄存器）；而同一进程的线程间逻辑地址空间是一样的，不需要切换页目录、刷新TLB。
> * 进程间通信比较复杂，而同一进程的线程由于共享代码段和数据段，所以通信比较容易。

### [TLB](https://www.cnblogs.com/linhaostudy/p/7771437.html)

TLB( Translation Look- aside buffer)专门用于缓存内存中的页表项,一般在MMU单元内部，页表一般存储在屋里内存中。当处理器要访问一个虚拟地址时,首先会在TLB中查询。如果TLB表项中没有相应的表项,称为TLB Miss,那么就需要访问页表来计算出相应的物理地址。如果TLB表项中有相应的表项,那么直接从TLB表项中获取物理地址,称为TLB命中。

### [程序计数器PC和指令指针寄存器IP](http://blog.sina.com.cn/s/blog_5ede281a0100sn4w.html)

* 程序计数器PC
  * 用指令事先编好的程序连续存放在内存程序区中，靠地址+1的方法连续取指执行”。在八位机8080CPU中是采用先取指后执行的串行操作的原理，而其中执行地址+1指令寻址的部件就是程序计数器PC。那么在程序的执行过程中，PC始终是指向下一条要执行的指令。
  * 结论：PC中的地址就是需要转移、循环、调用子程序和中断子程序等操作时的断点。
* 指令指针寄存器IP
  * 在向上兼容的十六位机8086CPU中首先分为两个功能部件，即总线接口部件BIU和执行部件EU，BIU负责取指令，EU负责译码执行。并且当BIU执行指令排队栈中的六个字节装满后，（8088CPU是4个字节），EU开始从指令排队栈的出栈口，取指令进行译码执行，同时BIU并行操作向入栈口补充一条取指令命令。
  * 指令指针IP则是指向下个条要取指的指令，而不是EU要执行的指令。而断点则应该是要执行的指令内存地址，而不是IP内的下一条要取指的指令地址。
* PC是模型机中的概念，IP是实际使用的，调试时我们发现，IP实现的就是PC的功能。

### 为什么有了进程还需要线程？

* 优点
  * 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量.
* 缺点
  * 进程在同一时间只能干一件事
  * 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性

## 用户态和内核态

### 概念
>
> * 用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。
> * 用户态拥有最低的特权级，内核态拥有较高的特权级。
> * 运行在用户态的程序不能直接访问操作系统内核数据结构和程序
> * 操作系统的数据都是存放于系统空间的，用户进程的数据是存放于用户空间的。
    *分开来存放，就让系统的数据和用户的数据互不干扰，保证系统的稳定性。
    * 分开存放，管理上很方便，而更重要的是，将用户的数据和系统的数据隔离开，就可以对两部分的数据的访问进行控制。这样就可以确保用户程序不能随便操作系统的数据，这样防止用户程序误操作或者是恶意破坏系统。

### [用户态和内核态可以通过指针传递数据吗？](http://blog.chinaunix.net/uid-26611973-id-3190018.html)

* 用户态不能访问内核态的指针
  * 为了实现内存的保护，防止越界访问而造成受保护内存的被非法修改，甚至造成系统的崩溃，这种直接传递数据指针来传递数据的方式是被禁止的。
* 内核态可以访问用户态的指针(有前提)
  * 必须保证用户态虚拟空间的指针（虚拟空间的地址），已经分配物理地址，否则指针传入内核态中将不会引发缺页异常而报错
* [内核中访问用户进程的地址的时候用copy_from_user，而不是用memcpy直接拷贝(或者说使用用户态指针)](https://blog.csdn.net/u014089131/article/details/56272892)
  * copy_from_user主要是这个函数提供了两个功能
    * 对用户进程传过来的地址范围进行合法性检查；
    * 当用户传来的地址没有分配物理地址时，定义了缺页处理后的异常发生地址，保证程序顺利执行；
    * 对于用户进程访问虚拟地址，如果还未分配物理地址，就会触发内核缺页异常，接着内核会负责分配物理地址，并修改映射页表。这个过程对于用户进程是完全透明的。但是在内核空间发生缺页时，必须显式处理，否则会导致内核出现错误
  * 直接使用memcpy时为什么没有出现异常
    * 只有用户传来的地址空间没有分配对应的物理地址时才会进行修复，如果用户进程之前已经使用过这段空间，代表已经分配了物理地址，自然不会发生缺页异常。

### 两种状态转换

* 系统调用
  * 用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作
* 异常
  * 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此异常的内核相关程序中，也就到了内核态，比如缺页异常。
* 外围设备中断
  * 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序
  * 比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等

## 存储器层次结构

### 层次结构

本地磁盘 -> 主存(DRAM) -> L3高速缓存(SRAM) -> L2高速缓存(SRAM) -> L1高速缓存(SRAM) -> L0寄存器

### 缓存思想
>
> * 位于K层的更快更小的存储设备作为位于K+1层更大更慢的存储设备的缓存
> * K+1层的存储器被划分成连续的数据对象组块，称为块，数据总是以块大小为传送单元在K和K+1层之间来回复制

### 缓存命中
>
> * 当程序需要K+1层的某个数据对象d时，首先在当前存储在K层的块中查找d，若d刚好缓存在k层中，则称为缓存命中
> * 若缓存不命中，则需要将K+1层中包含对象d的块缓存到K层中，若K层中满了，则需要替换现存的一个块

## 什么是虚拟内存

为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存，防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但**不需要映射到连续的物理内存**，也**不需要所有页都必须在物理内存中**。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

### [虚拟内存的好处](https://www.jianshu.com/p/baf3a13c47db)

* 可以更加高效的使用物理内存
  * 虚拟地址空间一开始并没有真正的对应物理地址，而是在真正使用的时候才去对应。
  * 通过虚拟内存置换算法在访问后边的地址空间的时候就可以将前边当前没有在访问的物理页释放掉，或者交换到硬盘中。这样这个物理页又可以去对应新的虚拟地址。从而使物理内存可以充分的利用。
* 内存管理
  * 为每个进程提供了一致的地址空间，简化内存管理
* 内存保护
  * 在使用虚拟地址的时候，暴露给程序员永远都是虚拟地址，而具体的物理地址在哪里，这个只有系统才了解。这样就提高了系统的封装性。
  * 保护了每个进程的地址空间不被其他进程破坏

## 虚拟内存页表寻址

### 分页

虚拟内存分割成虚拟页，物理内存被分割成物理页，用来作为磁盘和主存的传输单元。
虚拟页分为三个不相交的子集
>
> * 未分配的，不占磁盘空间
> * 缓存的，当前已缓存在物理内存中的已分配页，在页表中标志位为1
> * 未缓存的，未缓存在物理内存中的已分配页，在页表中标志位为0

### 页表

内存管理单元（MMU，属于硬件）管理着地址空间和物理内存的转换，操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，存储着程序地址空间到物理内存空间的映射表。

页表存放在物理内存中，物理页存放在物理内存中，虚拟页存放在磁盘上

### 页表寻址
>
> * 一个虚拟地址分为两部分，一部分存储页面号，一部分存储偏移量
> * 页表分为序号、页基地址、标志位
> * 访问虚拟地址，先通过页表查询页面号，查看标志位确认虚拟地址是否在物理内存中有缓存，然后由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移虚拟地址中的偏移量就得到最后的物理地址
> * 一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。

## 缺页中断

在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时(缓存不命中)，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：
>
> * 保护CPU现场
> * 分析中断原因
> * 转入缺页中断处理程序进行处理
> * 恢复CPU现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：
>
> * 在指令执行期间产生和处理缺页中断信号
> * 一条指令在执行期间，可能产生多次缺页中断
> * 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。

## 虚拟内存置换算法

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。

当前操作系统最常采用的缺页置换算法如下：
>
> * 先进先出(FIFO)算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。

> * 最近最少使用（LRU）算法: 置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

当前最常采用的就是LRU算法。

## 说一下LINUX系统中的锁

互斥锁，读写锁，自旋锁
>
> * 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。**当获取锁操作失败时，线程会进入睡眠**，等待锁释放时被唤醒

> * 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它**获取写锁失败的线程都会进入睡眠状态**，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

> * 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是**当获取锁操作失败时，不会进入睡眠，而是会在原地自旋**，循环检测锁的保持者是否释放，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。

## 自旋锁发生死锁

## 死锁产生的条件

多个并发进程因争夺系统资源而产生相互等待的现象。

* 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；

* 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源

* 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放

* 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链 ，环路中每个进程都在等待下一个进程所占有的资源

## 如何避免死锁

* **破坏请求和等待条件。** 所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源
* **破坏不可抢占条件。** 当进程新的资源未得到满足时，释放已占有的资源
* **破坏环路等待条件。** 系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反

## 死锁检测和死锁恢复

* 死锁检测
  * 每种类型一个资源的死锁检测
  * 每种类型多个资源的死锁检测
* 死锁恢复
  * **抢占恢复。** 从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态
  * **回滚恢复。** 周期性地检查进程的状态（包括请求的资源），将其写入一个文件，当发生死锁，回滚到之前的某个时间点
  * **杀死进程恢复。** 终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。

## [信号处理机制](http://www.360doc.com/content/16/0804/10/30953065_580685165.shtml)

## [哪两个信号不能忽略](https://www.cnblogs.com/Lynn-Zhang/p/5677118.html)

SIGKILL和SIGSTOP，这两种信号不能被忽略

* 它们向超级用户提供一种使进程终止或停止的可靠方法。
* 如果忽略某些由硬件异常产生的信号（例如非法存储访问或除以0），则进程的行为是示定义的。

## [原子操作和锁机制](https://blog.csdn.net/CringKong/article/details/79966161)

[原子操作实现同步](https://blog.csdn.net/c472769019/article/details/82663148)

---

## 数据结构

# 查找算法
>
> * [二叉树基础](#二叉树基础)
> * [最大堆和最小堆](#最大堆和最小堆)
> * [二分查找](#二分查找)
> * [二叉排序树](#二叉排序树)
> * [平衡二叉树](#平衡二叉树)
> * [多路查找树2-3树](#多路查找树2-3树)
> * [红黑树](#红黑树)
> * [B/B+树](#BB树)
> * [哈希表](#哈希表)
> * [跳表](#跳表)
> * [位图](#位图)

# 数组和链表
>
> * [数组和链表的区别](#数组和链表的区别)

# 赫夫曼编码
>
> * [赫夫曼树](#赫夫曼树)
> * [赫夫曼编码](#赫夫曼编码)

## 二叉树基础

* 二叉树定义
  * n个结点的有限集合，该集合为空集，或者一个根节点和两棵互不相交的、分别称为根节点的左子树和右子树的二叉树组成
* 满二叉树
  * 一棵二叉树中所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上
* 完全二叉树
  * 一棵有n个结点的二叉树按层序编号，编号为i的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同
* 二叉树的性质
  * 非空二叉树第 i 层最多 2^(i-1) 个结点 （i >= 1）
  * 深度为 k 的二叉树最多 2^k - 1 个结点 （k >= 1）
  * 度为 0 的结点数为 n0，度为 2 的结点数为 n2，则 n0 = n2 + 1
  * 有 n 个结点的完全二叉树深度 k = ⌊ log2(n) ⌋ + 1
  * 对于含 n 个结点的完全二叉树中编号为 i （1 <= i <= n） 的结点
    * 若 i = 1，为根，否则双亲为 ⌊ i / 2 ⌋
    * 若 2i > n，则 i 结点没有左孩子，否则孩子编号为 2i
    * 若 2i + 1 > n，则 i 结点没有右孩子，否则孩子编号为 2i + 1

## 最大堆和最小堆

堆是完全二叉树，根据结点和左右孩子的大小关系，分为最大堆和最小堆

* 最大堆
  * 每个结点的值都大于或等于其左右孩子结点的值
* 最小堆
  * 每个结点的值都小于或等于其左右孩子结点的值

## 二分查找

二分查找适用于有序数组

* 查找时间复杂度O(logn)

## 二叉排序树

* 查找时间复杂度O(logn)，最坏情况变成右斜树O(n)

二叉排序树，又称二叉搜索树，若二叉排序树不为空，则具有下列性质
>
> * 若左子树不为空，则左子树上所有结点的值小于根节点的值
> * 若右子树不为空，则右子树上所有结点的值大于根节点的值

## 平衡二叉树

* 查找时间复杂度O(logn)，插入和删除时间复杂度O(logn)

平衡二叉树是**二叉排序树**，每一个结点左右子树高度之差的绝对值不超过1

## [多路查找树2 3树](https://blog.csdn.net/u014688145/article/details/67636509)

多路查找树，每一个结点的孩子数可以多于两个，每一个节点处可以存储多个元素

### 2-3树

每一个结点都具有两个孩子(2结点)或三个孩子(3结点)
一个2结点包含一个元素和两个孩子
一个3结点包含一小一大两个元素和三个孩子

## [红黑树](https://www.cnblogs.com/yangecnu/p/Introduce-Red-Black-Tree.html)

* 查找时间复杂度O(logn)，插入和删除时间复杂度O(logn)

* 红黑树的五个性质（性质没法解释），红黑树是这样的树！！！
>
> * 每个结点非红即黑
> * 根结点为黑色
> * 每个叶结点（叶结点即实际叶子结点的NULL指针或NULL结点）都是黑的;
> * 若结点为红色，其子节点一定是黑色（没有连续的红结点）
> * 对于每个结点，从该结点到其后代叶结点的简单路径上，均包含相同数目的黑色结点（叶子结点要补充两个NULL结点）
> * 有了五条性质，才有一个结论：**通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡**。
>
* 平衡树和红黑树的区别
  * **AVL树是高度平衡的**，频繁的插入和删除，会引起频繁的调整以重新平衡，导致效率下降
  * **红黑树不是高度平衡的**，算是一种折中，插入最多两次旋转，删除最多三次旋转，调整时新插入的都是红色。

* 为什么红黑树的插入、删除和查找如此高效？
  * 插入、删除和查找操作与树的高度成正比，因此如果平衡二叉树不会频繁的调整以重新平衡，那它肯定是最快的，但它需要频繁调整以保证平衡
  * 红黑树算是一种折中，保证最长路径不超过最短路径的二倍，这种情况下插入最多两次旋转，删除最多三次旋转，因此比平衡二叉树高效。

* 红黑树为什么要保证每条路径上黑色结点数目一致？
  * 为了保证红黑树保证最长路径不超过最短路径的二倍
  * 假设一个红黑树T，其到叶节点的最短路径肯定全部是黑色节点（共B个），最长路径肯定有相同个黑色节点（性质5：黑色节点的数量是相等），另外会多几个红色节点。性质4（红色节点必须有两个黑色儿子节点）能保证不会再现两个连续的红色节点。所以最长的路径长度应该是2B个节点，其中B个红色，B个黑色。

## [B/B+树](https://blog.csdn.net/du5006150054/article/details/82379210)

B树是一种平衡的多路查找树，2-3树和2-3-4树都是B树的特例，结点最大的孩子数目称为B树的阶。

### B/B+树的区别

以（key，value）二元组来存储信息

#### B树

* B树中的每个结点中既包含key，也包含value值，每个结点占用一个盘块的磁盘空间，一个结点上有两个升序排序的关键字和三个指向子树根结点的指针，指针存储的是子结点所在磁盘块的地址。
* **缺点**：每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。

#### B+树

* 所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度
* B+树的头指针有两个，一个指向根节点，另一个指向关键字最小的元素，因此B+树有两种遍历的方式
  * 从根节点开始随机查询
  * 从最小关键词顺序查询
* 优点
  * 由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。
  * B+树的叶子结点都是相连的，因此对整棵树的便利只需要一次线性遍历叶子结点即可，方便随机查找和范围查找

#### 区别
>
> * 非叶子节点只存储键值信息，该值是其子树中的最大或最小值
> * 所有叶子节点之间都有一个链指针。
> * 数据记录都存放在叶子节点中，叶子结点按照关键字的大小自小而大顺序连接
> * n棵子树的结点中包含n个关键字
> * 非叶子结点中的元素会在子树根结点中再次列出

### [B树和红黑树应用场景](https://blog.csdn.net/zcf9916/article/details/84915506)

* B树
  * B/B+树是为了磁盘或其它存储设备而设计的一种平衡多路查找树(相对于二叉,B树每个内节点有多个分支),与红黑树相比,在相同的的节点的情况下,一颗B/B+树的高度远远小于红黑树的高度.
* 红黑树
  * IO多路复用epoll的实现采用红黑树组织管理sockfd，以支持快速的增删改查.

#### 实例

* 假定一个节点可以容纳100个值，那么3层的B树可以容纳100万个数据，如果换成二叉查找树，则需要20层！假定操作系统一次读取一个节点，并且根节点保留在内存中，那么B树在100万个数据中查找目标值，只需要读取两次硬盘。

## [哈希表](https://www.cnblogs.com/yangecnu/p/Introduce-Hashtable.html)

哈希表是一种以键-值(key-indexed) 存储数据的结构，我们只要输入待查找的值即key，即可查找到其存储位置，在该位置上存储着对应的数据

### 哈希表的实现

* 主要包括构造哈希和处理哈希冲突
  * **使用哈希函数将被查找的键转换为数组的索引。**方法有**直接地址法、平方取中法、除留余数法**等。理想的情况下，不同的键会被转换为不同的索引值，但是在有些情况下我们需要处理多个键被哈希到同一个索引值的情况。所以哈希查找的第二个步骤就是处理冲突。
  * **处理哈希碰撞冲突。**有很多处理哈希碰撞冲突的方法，如**拉链法(哈希桶)、线性探测法(开放定址法)、再哈希法、公共溢出区法**。

### 构造哈希

* 直接地址法
  * 直接用key或key的线性函数值作为索引
  * 如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。
* 平方取中法
  * 将key平方后取中间的几位数作为索引，可以是3位或4位
* 除留余数法
  * 最常用的构造哈希函数的方法，直接对key取模，也可以平方后取模。
  * 获取**正整数哈希值**最常用的方法是使用除留余数法，即对于大小为素数M的数组，对于任意正整数k，计算k除以M的余数。**M一般取素数**。

#### 字符串哈希值

* 将字符串作为键的时候，可以将它作为一个大的整数，将组成字符串的每一个字符取ASCII值然后进行哈希，采用Horner计算字符串哈希值。
* 如果对每个字符去哈希值可能会比较耗时，所以可以通过间隔取N个字符来获取哈西值来节省时间

```C++
int hash = 0;
char *str = "abcdef";
for(int i = 0;i < strlen(str);i++){
 hash = 31*hash + (int)str[i];
}
cout<<hash<<endl;
```

### 处理哈希冲突

#### 拉链法（哈希桶法）

* 基本思想
  * 将大小为M的数组的每一个元素指向一个链表，链表中的每一个结点都存储散列值为该索引的键值对。注意选择足够大的M，使得所有的链表都尽可能的短小，以保证查找的效率
* 拉链法查找
  * 根据散列值找到索引对应的链表，
  * 沿着链表顺序找到相应的键

#### 线性探测法（开放定址法）

基本思想：f(key) = (f(key) + d) MOD M

* 线性探测
  * 当碰撞发生时即一个键的散列值被另外一个键占用时，直接检查散列表中的下一个位置即将索引值加1
* 二次探测
  * 索引值位移量不为1，为1，-1，2，-2...的平方
* 随机探测
  * 索引值位移量采用随机函数计算得到。随机种子产生伪随机数，每次得到的随机序列相同

#### 再哈希法

使用哈希函数去散列一个输入的时候，输出是同一个位置就再次散列，直至不发生冲突位置，但每次冲突都要重新散列，计算时间增加，另外需要准备多个哈希函数

#### 公共溢出区法

建立一个公共溢出区域，把hash冲突的元素都放在该溢出区里。查找时，如果发现hash表中对应桶里存在其他元素，还需要在公共溢出区里再次进行查找。

### 为什么哈希桶的长度和除留余数法的M为质数？

设有一个哈希函数：H( c ) = c % N;
当N取一个合数时，最简单的例子是取2^n，比如说取2^3=8,这时候
H(11100(二进制)) = H(28) = 4
H(10100(二进制)) = H(20) = 4

* c的二进制**第4位（从右向左数）就“失效”**了，也就是说，无论第c的4位取什么值，都会导致H( c )的值一样．这时候c的第四位就根本不参与H( c )的运算，这样H( c )就无法完整地反映c的特性，增大了导致冲突的几率．
* 取其他合数时，都会不同程度的导致c的某些位”失效”，从而在一些常见应用中导致冲突．
* 取质数，基本可以保证c的每一位都参与H( c )的运算，从而在常见应用中减小冲突几率．

## [跳表](https://www.cnblogs.com/a8457013/p/8251967.html)

* 查找时间复杂度O(logn)，插入、删除时间复杂度O(logn)
* 用于有序链表的查找，类似二分查找操作的链表

### 基本思想

把链表中的一些节点提取出来作为索引，为了提高效率可以逐级提取作为索引

* 原始链表
  * 14 → 23 → 34 → 43 → 50 → 59 → 66 → 72
  * 原始链表查找复杂度O(n)

* 跳表
  * 性质
    * 由很多层结构组成
    * 每一层都是一个有序的链表
    * 最底层(Level 1)的链表包含所有元素
    * 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
    * 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。

  * 原始链表转换成跳表

    14 &emsp;&ensp; &emsp;&emsp;&ensp;→&ensp;&emsp;&emsp;&emsp;&emsp;50

    &ensp;↓&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;↓

    14&emsp;&emsp;→&emsp;&ensp;34&emsp;&ensp;→&emsp;&emsp;50&emsp;&ensp;→&emsp;&emsp;66

    &ensp;↓&emsp;&emsp;&emsp;&emsp;&emsp;↓&emsp;&emsp;&emsp;&emsp;&emsp;↓&emsp;&emsp;&emsp;&emsp;&emsp;↓

    14&nbsp;&nbsp;→&nbsp;23&nbsp;&nbsp;→&nbsp;34&nbsp;&nbsp;→&nbsp;43&nbsp;&nbsp;→&nbsp;50&nbsp;&nbsp;→&nbsp;59&nbsp;&nbsp;→&nbsp;66&nbsp;&nbsp;→&nbsp;&nbsp;72

    第二级索引 - 第一级索引 - 原始链表

### [跳表的查找、插入和删除](https://www.cnblogs.com/seniusen/p/9870398.html)

* 查找
  * 查找时间复杂度为O(logn)
  * 如果链表中总共有 n 个结点，那么第一级索引就有 n/2 个结点，第二级索引就有 n/4 个结点，以此类推，那么第 k 级索引就有 n/(2^k) 个结点。如果最高级索引有 2 个结点，那总的索引级数 k=log2n−1，如果我们算上原始链表的话，那也就是总共有 log2n 级。

* 插入
  * 先查找再插入，插入时间复杂度O(logn)
  * 当我们不停地往跳表中插入数据的时候，如果我们不更新索引，就有可能出现某两个结点之间数据非常多的情况。极端情况下，跳表还会退化为单链表。
  * 我们需要某种手段来维护索引与原始链表大小之间的平衡，也就是说，如果链表结点变多了，索引值就相应地增加一些
  * 可以选择同时也将这个数据插入到部分索引层中。而插入到哪些索引层中，则由一个随机函数生成一个随机数字来决定

### 跳表和红黑树的对比

* 插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度和跳表是一样
* 跳表的优点
  * 代码相对简单
  * 按照区间查找数据这个操作，红黑树的效率没有跳表高。跳表可以在 O(logn) 时间复杂度定位区间的起点，然后在原始链表中顺序向后查询就可以了，这样非常高效。
  * 删除一段区间的数据，相对于红黑树容易

## [位图](https://blog.csdn.net/moakun/article/details/79927791)

[位图一](https://blog.csdn.net/varyall/article/details/79662029)、[位图二](https://blog.csdn.net/wypblog/article/details/8237956)

### 基本思想

bitmap(位图)，每一位存放某种状态，通常用来判断某个数据是否存在。32位机器上，整型int在内存中占32bit(4 byte = 4 * 8 bit)，可以用对应的32bit对应十进制的0-31个数。

### 用途

排序，去重，查找

### map映射表

**基本思想**
假设需要排序或者查找的总数N=10000000，那么我们需要申请内存空间的大小为**int a[1 + N/32]**，其中a[0]在内存中占32为可以对应十进制数0-31，依次类推：
bitmap表为：  
a[0]--------->0-31  
a[1]--------->32-63  
a[2]--------->64-95  
a[3]--------->96-127  
..........

**位映射步骤**

* 求十进制0-N对应在数组a中的下标：
  * 十进制0-31，对应在a[0]中，先由十进制数n转换为与32的模(商)可转化为对应在数组a中的下标。比如n=24,那么 n/32=0，则24对应在数组a中的下标为0。又比如n=60,那么n/32=1，则60对应在数组a中的下标为1，同理可以计算0-N在数组a中的下标。

* 求0-N对应每个下标0-31中的数：
  * 十进制0-31就对应0-31，而32-63则对应也是0-31，即给定一个数n可以通过模32的余数求得对应0-31中的数。

* 利用移位0-31使得对应位为1.

### 应用

* 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。
  * **“内存空间不足以容纳这2.5亿个整数”我们可以快速的联想到Bit-map**
  * 使用两个位图
    * 第一个Bitmap存储的是整数是否出现
    * 如果再次出现，则在第二个Bitmap中设置
  * 使用一个位图
    * 遍历一次这2.5亿个数字，如果对应的状态位为00，则将其变为01；如果对应的状态位为01，则将其变为11；如果为11，,对应的转态位保持不变。
    * 最后，我们将状态位为01的进行统计，就得到了不重复的数字个数，时间复杂度为O(n)。

### 扩展-布隆过滤器

**基本思想**

* 当一个元素被加入集合中时,通过k个散列函数将这个元素映射成一个位数组中的k个点,并将这k个点全部置为1.
* Bloom Filter使用k个相互独立的哈希函数（Hash Function），它们分别将集合中的每个元素映射到{1,…,m}的范围中。对任意一个元素x，第i个哈希函数映射的位置hi(x)就会被置为1（1≤i≤k）。注：如果一个位置多次被置为1，那么只有第一次会起作用，后面几次将没有任何效果。
* 在判断y是否属于这个集合时，对y应用k次哈希函数，若所有hi(y)的位置都是1（1≤i≤k），就认为y是集合中的元素，否则就认为y不是集合中的元素。

**缺点**

有一定的误判率，当判断某个元素在集合中，有可能是其他的元素的位；若集合中不存在该元素，则一定不存在

## 数组和链表的区别

* 存储
  * 数组时连续的内存空间，链表不需要连续
* 长度
  * 数组的长度需要预先确定，若超出数组则会溢出
  * 链表的长度是动态扩展的
* 随机访问
  * 数组可以随机访问，时间复杂度为O(1)
  * 链表不支持随机访问，平均需要O(n)
* 插入、删除
  * 数组其实位置的插入和删除， 时间复杂度为O(n)
  * 链表的时间复杂度为O(1)

### 什么是随机访问

比如first是第一个元素的地址，现在想访问第N个元素。
随机访问：直接first+N，便可以得到第N个元素的地址，因为这些相邻元素是按顺序连续存储的。比如普通数组就是可随机访问的。

## [赫夫曼树](https://www.cnblogs.com/kubixuesheng/p/4397798.html)

### 基本概念

* 路径长度
  * 从树中一个结点到另一个结点之间的分支构成两个结点之间的路径，路径上的分支数目称为路径长度，为结点数-1
  * 树的路径长度是从树根到每一结点的路径长度之和
* 带权路径长度
  * 若结点带权，则带权路径长度为**该结点到树根之间的路径长度**与**结点上权重**的乘积
* 赫夫曼树
  * 带权路径长度WPL(weight path length)最小的二叉树为赫夫曼树

### 构建赫夫曼树(自下而上)

* 根据给定的n个权值{w1,w2,…,wn}构成二叉树集合F={T1,T2,…,Tn},其中每棵二叉树Ti中只有一个带权为wi的根结点,其左右子树为空.
* 在F中选取两棵根结点权值最小的树作为左右子树构造一棵新的二叉树,且置新的二叉树的根结点的权值为左右子树根结点的权值之和.
* 在F中删除这两棵树,同时将新的二叉树加入F中.
* 重复2、3,直到F只含有一棵树为止.(得到哈夫曼树)

### 构建示例

有4 个结点 a, b, c, d，权值分别为 7, 5, 2, 4，构造哈夫曼树。

* 根据给定的n个权值{7,5,2,4}构成二叉树集合F={T1,T2,…,Tn},其中每棵二叉树Ti中只有一个带权为wi的根结点,其左右子树为空.
  * F中有四个二叉树{a(7),b(5),c(2),d(4)}，每个二叉树左右子树为空，只有根节点
* 在F中选取两棵根结点权值最小的树作为左右子树构造一棵新的二叉树,且置新的二叉树的根结点的权值为左右子树根结点的权值之和.
  * 先取最小的c和d，新结点为m，左右子树为c和d，m权值为6
* 在F中删除这两棵树,同时将新的二叉树加入F中.
  * 在F中删除c和d，加入m，此时F中有三棵树{a(7),b(5),m(6)}
* 重复2、3,直到F只含有一棵树为止

## 赫夫曼编码

用于解决电报数据传输，赫夫曼编码使得电报编码长度最短，且可以保证唯一性

* 前缀编码
  * 设计长短不等的编码，必须是任一字符的编码都不是另一个字符编码的前缀，这种编码称为前缀编码
* 赫夫曼编码
  * 需要变得字符集为{d1,d2,…,dn}，各个字符在电文中出现的次数或频率为{w1,w2,…,wn}，以d1,d2,…,dn为叶子结点，以w1,w2,…,wn为相应叶子结点的权值来构建一棵赫夫曼树
  * 规定赫夫曼树的左分支代表0，右分支代表1，从根结点到叶子结点所经过的路径分支所组成的0,1序列变为该结点对应的字符编码

### 译码

* 从哈夫曼树根开始，对待译码电文逐位取码。
* 若编码是“0”，则向左走；若编码是“1”，则向右走，一旦到达叶子结点，则译出一个字符；
* 再重新从根出发，直到电文结束。

---

## 海量数据处理

# 海量数据处理

海量数据，不能一次加载到内存中

> * 海量数据topK(最大和最小k个数)，第k大，第k小的数
> * 海量数据判断一个整数是否存在其中
> * 海量数据找出不重复的数字
> * 找出A,B两个海量url文件中共同的url

## 海量数据topK

最大K使用最小堆，最小K使用最大堆，这里以最大K为例
>
> * 海量数据hash分块
> * 维护最小堆的K个数据的数据容器
> * 堆中数据是topK大的数据，堆顶的数据是第K大数据

1. 先将海量数据hash再取模m，分成m个小文件，hash(num)%m，也可以直接取模
2. 在每个小文件中维护K个数据的最小堆，堆顶是当前堆中的最小值
3. 遍历每个小文件中剩余的数据，与堆顶的数据进行比较，更新最小堆中的数据
4. 生成m * K个数据，然后对这些数据再进行排序，或者再次通过维护最小堆

**变形**

1. 第K大不只是topK，此时堆顶数据即是
2. 只求最大或最小
3. 海量数据不仅仅是整数，也可以是字符串
4. 海量数据按照出现的次数或者频率排序，topK

> * 海量数据按照出现的次数或者频率排序，topK
>
1. 先将海量数据hash再取模m，分成m个小文件，hash(num)%m
2. 扫描每个小文件的数据，通过hash_map建立值和频率的键值对
3. 以出现的频率维护最小堆的K个数据的数据容器
4. 遍历每个小文件中剩余的数据，与堆顶的数据进行比较，更新最小堆中的数据
5. 生成m * K个数据，然后对这些数据再进行排序，或者再次通过维护最小堆

## 找出A,B两个海量url文件中共同的url

题目：两个文件各存50亿个url，每个url64个字节，内存限制4G，找出A,B共同的url
>
> * 单个文件读取肯定超出内存大小，所以还是采取之前的分治思想，大化小，对A/B分别取模分成1000个文件存储，这样两个文件中相同的url都被分到相同的小文件中，若有一方的小文件还是太大，则可以扩大分块或者通过不同hash函数继续hash（若继续，两方应该一起），50亿url算下来每个文件300M。
> * 对小文件求公共url的时候可以使用hash_set去重。A文件Set建立后另外一个文件的内容遍历跟Set中内容比对，如果相等则记录

## [bitmap](https://blog.csdn.net/qq_22080999/article/details/81975889)

bitmap一般是total/32 + 1个数组，从a[0]开始，每组是32bit表示，对应位的0或1表示十进制的0-31是否存在，可以用于快速排序，快速去重，快速查询

## 海量数据判断一个整数是否存在其中

> * 分治思想，首先分成小文件，然后建立HashTable进行统计
> * 可以使用BitMap，每个数分配1Bit，0不存在，1存在建立完毕扫描数据把对应位置的比特位描成0/1，最后查找整数的位置是否为1（通过商判断在哪个数组中，余数判断哪一位）

## 海量数据找出不重复的数字/仅出现一次的数据
>
> * 可以使用BitMap，每个数分配两Bit，00不存在，01出现一次，10出现多次，11没意义。需要内存2^32 *8* 2bit，建立完毕扫描数据把对应位置的比特位描成00/01/10/11，最后查找01
>
---

## c++面向对象

# C++面向对象知识

> * [内存字节对齐](#内存字节对齐)
> * [面向对象三大特性](#面向对象三大特性)
> * [双冒号、using和namespace](#双冒号using和namespace)
> * [内联函数和函数重载](#内联函数和函数重载)
> * [虚函数可以是内联函数吗](#虚函数可以是内联函数吗)
> * [构造函数/析构函数](#构造函数析构函数)
> * [拷贝构造函数与深浅拷贝](#拷贝构造函数与深浅拷贝)
> * [只在堆上/栈上创建对象](#只在堆上栈上创建对象)
> * [this指针](#this指针)
> * [常函数和常对象](#常函数和常对象)
> * [delete this合法吗](#delete-this合法吗)
> * [为什么空类大小不为0](#为什么空类大小不为0)
> * [静态成员变量与静态成员函数](#静态成员变量与静态成员函数)
> * [能否通过初始化列表初始化静态成员变量](#能否通过初始化列表初始化静态成员变量)
> * [初始化列表的好处和使用条件](#初始化列表的好处和使用条件)
> * [友元全局函数、友元类、友元成员函数](#友元全局函数友元类友元成员函数)
> * [运算符重载及++重载实现](#运算符重载及重载实现)
> * [继承方式、对象模型、同名处理](#继承方式对象模型同名处理)
> * [多继承和菱形继承](#多继承和菱形继承)
> * [静态函数可以是虚函数吗](#静态函数可以是虚函数吗)
> * [类型兼容性原则-为什么会有多态](#类型兼容性原则-为什么会有多态)
> * [重载、覆盖、重写](#重载覆盖重写)
> * [多态实现的基础](#多态实现的基础)
> * [静态多态和动态多态](#静态多态和动态多态)
> * [虚函数指针和虚函数表](#虚函数指针和虚函数表)
> * [函数指针与指针函数](#函数指针与指针函数)
> * [怎么理解多态和虚函数](#怎么理解多态和虚函数)
> * [构造函数能否实现多态/虚函数指针什么时候初始化](#构造函数能否实现多态虚函数指针什么时候初始化)
> * [构造函数能否是虚函数](#构造函数能否是虚函数)
> * [抽象类和纯虚函数](#抽象类和纯虚函数)
> * [虚析构和纯虚析构](#虚析构和纯虚析构)
> * [为什么析构函数必须是虚函数](#为什么析构函数必须是虚函数)
> * [为什么C++默认的析构函数不是虚函数](#为什么C++默认的析构函数不是虚函数)
> * [类模板和函数模板](#类模板和函数模板)

## [内存字节对齐](https://www.cnblogs.com/jijiji/p/4854581.html)
>
> * `#pragma pack(n)` 表示的是设置n字节对齐,windows默认是8，linux是4

```C++
struct A{
    char a;
    int b;
    short c;
};
```
>
> * char占一个字节，起始偏移为零，int占四个字节，min(8,4)=4；所以应该偏移量为4，所以应该在char后面加上三个字节，不存放任何东西，short占两个字节，min(8,2)=2;所以偏移量是2的倍数，而short偏移量是8，是2的倍数，所以无需添加任何字节，所以第一个规则对齐之后内存状态为0xxx|0000|00
> * 此时一共占了10个字节，但是还有结构体本身的对齐，min(8,4)=4；所以总体应该是4的倍数，所以还需要添加两个字节在最后面，所以内存存储状态变为了 0xxx|0000|00xx，一共占据了12个字节

* 内存对齐规则
  * 对于结构的各个成员，第一个成员位于偏移为0的位置，以后的每个数据成员的偏移量必须是  min(#pragma pack()指定的数,这个数据成员的自身长度)的倍数
  * 在所有的数据成员完成各自对齐之后，结构或联合体本身也要进行对齐，对齐将按照 #pragam pack指定的数值和结构或者联合体最大数据成员长度中比较小的那个，也就是  min(#pragram pack() , 长度最长的数据成员)

* 需要对齐的原因
  * 平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据，某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常
  * 硬件原因：经过内存对齐之后，CPU的内存访问速度大大提升。访问未对齐的内存，处理器要访问两次（数据先读高位，再读低位），访问对齐的内存，处理器只要访问一次，为了提高处理器读取数据的效率，我们使用内存对齐

## 面向对象三大特性

通过类创建一个对象的过程叫实例化，实例化后使用对象可以调用类成员函数和成员变量，其中类成员函数称为行为，类成员变量称为属性。类和对象的关系：类是对象的抽象，对象是类的实例

* 封装
  * 把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。
  * public，private，protected
* 继承
  * 基类（父类）——> 派生类（子类）
* 多态

## 双冒号、using和namespace

* namespace主要用来解决命名冲突的问题
  * 必须在全局作用域下声明
  * 命名空间下可以放函数，变量、结构体和类
  * 命名空间可以嵌套命名空间
  * 命名空间是开放的，可以随时加入新成员（添加时只需要再次声明namespace，然后添加新成员即可

* 双冒号::作用域运算符
  * 全局作用域符（::name）：用于类型名称（类、类成员、成员函数、变量等）前，表示作用域为全局命名空间
  * 类作用域符（class::name）：用于表示指定类型的作用域范围是具体某个类的
  * 命名空间作用域符（namespace::name）:用于表示指定类型的作用域范围是具体某个命名空间的

* using分为using声明和using编译指令
  * `using std::cout; //声明`
  * `using namespace std; //编译指令`
  * 尽量使用声明而不是编译指令，不同命名空间中可能会有相同的变量名，编译指令执行两个命名空间后，会产生二义性

## 内联函数和函数重载

* 内联函数
  * 相当于把内联函数里面的内容写在调用内联函数处；
  * 相当于不用执行进入函数的步骤，直接执行函数体；
  * 相当于宏，却比宏多了类型检查，真正具有函数特性；
  * 不能包含循环、递归、switch 等复杂操作；
  * 在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数，内联函数对于编译器而言只是一个建议，编译器不一定会接受这种建议，即使没有声明内联函数，编译器可能也会内联一些小的简单的函数。

* C++的函数名称可以重复，称为函数重载。
  * 其中必须在同一作用域下的函数名称相同，不能是一个在全局，一个局部，或者不同的代码块中
  * 可以根据函数参数的个数、类型（const也可以作为重载条件）、顺序不同进行函数重载，但**不能用函数返回值进行重载**
  * 当函数重载遇到函数默认参数时，要注意二义性。

## 虚函数可以是内联函数吗

* 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。
* 内联是在编译期内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。
* inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类（如 Base::who()），这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。

## 构造函数/析构函数

构造函数和析构函数，分别对应变量的初始化和清理，变量没有初始化，使用后果未知；没有清理，则会内存管理出现安全问题。
当对象结束其生命周期，如对象所在的函数已调用完毕时，系统会自动执行析构函数
>
> * 构造函数：与类名相同，没有返回值，不写void，**可以发生重载**，可以有参数，编译器自动调用，只调用一次。
> * 析构函数：~类名，没有返回值，不写void，**不可以发生重载**，不可以有参数，编译器自动调用，只调用一次。

* 构造函数
  * 系统会默认给一个类提供三个函数：默认构造函数（无参，函数体为空）、默认拷贝构造和析构函数（无参，函数体为空），其中默认拷贝构造可以实现简单的值拷贝。
  * 提供了有参构造函数，就不提供默认构造函数；提供了拷贝构造函数，就不会提供其他构造函数，若自己定义可有参构造，也需要自定义无参构造函数

* 析构函数
  * 如果一个类中有指针，且在使用的过程中动态的申请了内存，那么最好自定义析构函数，在销毁类之前，释放掉申请的内存空间，避免内存泄漏

## 拷贝构造函数与深浅拷贝

拷贝构造函数的参数必须加const，因为防止修改，本来就是用现有的对象初始化新的对象。

* 拷贝构造函数的使用时机
  * 使用已经创建好的对象初始化新对象 `A a; A b = a; A c(a); b = c;//b = c不是初始化，调用赋值运算符`
  * 以值传递的方式来给函数参数传值
  * 以值方式返回局部对象（不常用，一般不返回局部对象）

* 深拷贝和浅拷贝
只有当对象的成员属性在堆区开辟空间内存时，才会涉及深浅拷贝，如果仅仅是在栈区开辟内存，则默认的拷贝构造函数和析构函数就可以满足要求。
  * **浅拷贝**：使用默认拷贝构造函数，拷贝过程中是按字节复制的，对于指针型成员变量只复制指针本身，而不复制指针所指向的目标，因此涉及堆区开辟内存时，会将两个成员属性指向相同的内存空间，从而在释放时导致内存空间被多次释放，使得程序down掉。
  * **浅拷贝的问题**：当出现类的等号赋值时，系统会调用默认的拷贝函数——即浅拷贝，它能够完成成员的一一复制。当数据成员中没有指针时，浅拷贝是可行的。但当数据成员中有指针时，如果采用简单的浅拷贝，则两类中的两个指针将指向同一个地址，当对象快结束时，会调用两次free函数，指向的内存空间已经被释放掉，再次free会报错；另外，一片空间被两个不同的子对象共享了，只要其中的一个子对象改变了其中的值，那另一个对象的值也跟着改变了所以，这时，必须采用深拷贝
  * **深拷贝**：自定义拷贝构造函数，在堆内存中另外申请空间来储存数据，从而解决指针悬挂的问题。**需要注意自定义析构函数中应该释放掉申请的内存**

我们在定义类或者结构体，这些结构的时候，最后都重写拷贝函数，避免浅拷贝这类不易发现但后果严重的错误产生

## 只在堆上/栈上创建对象
>
> * **只能在堆上生成对象：将析构函数设置为私有。**
原因：C++是静态绑定语言，编译器管理栈上对象的生命周期，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性。若析构函数不可访问，则不能在栈上创建对象。
> * **只能在栈上生成对象：将new 和 delete 重载为私有。**
原因：在堆上生成对象，使用new关键词操作，其过程分为两阶段：第一阶段，使用new在堆上寻找可用内存，分配给对象；第二阶段，调用构造函数生成对象。
将new操作设置为私有，那么第一阶段就无法完成，就不能够再堆上生成对象。

## this指针

* **为什么会有this指针**
在类实例化对象时，只有非静态成员变量属于对象本身，剩余的静态成员变量，静态函数，非静态函数都不属于对象本身，因此非静态成员函数只会实例一份，多个同类型对象会共用一块代码，由于类中每个实例后的对象都有独一无二的地址，因此不同的实例对象调用成员函数时，函数需要知道是谁在调用它，因此引入了this指针。
* **this指针的作用**
this指针是隐含在对象成员函数内的一种指针。当一个对象被创建后，它的每一个成员函数都会含有一个系统自动生成的隐含指针this。this指针指向被调用的成员函数所属的对象（谁调用成员函数，this指向谁），*this表示对象本身，**非静态成员函数中才有this，静态成员函数内部没有**。
  * this 并不是一个常规变量，而是个右值，所以不能取得 this 的地址（不能 &this）。
  * 对非静态成员函数默认添加了this指针，类型为classname *const this
* **this指针使用**
  * 当形参与成员变量名相同时，用this指针来区分
  * 为实现对象的链式引用，在类的非静态成员函数中返回对象本身，可以用return *this，this指向对象，/*this表示对象本身。

## 常函数和常对象

`void func() const //常函数，此处func为类成员函数`
`const Person p2; //常对象`

* 常函数修饰的是this指针，不允许修改this指针指向的值，如果执意要修改常函数，可以在成员属性前加**mutable**。
* 常对象不允许修改属性，不可以调用普通成员函数，可以调用常函数。

## delete this合法吗

合法，但有前提：

* 必须保证 this 对象是通过 new（不是 new[]、不是 placement new、不是栈上、不是全局、不是其他对象成员）分配的
* 必须保证调用 delete this 的成员函数是最后一个调用 this 的成员函数
* 必须保证成员函数的 delete this 后面没有调用 this 了
* 必须保证 delete this 后没有人使用了

## 为什么空类大小不为0

sizeof(空class) = 1，为了确保两个不同对象的地址不同。

## 静态成员变量与静态成员函数

若将成员变量声明为static，则为静态成员变量，与一般的成员变量不同，无论建立多少对象，都只有一个静态成员变量的拷贝，静态成员变量属于一个类，所有对象共享。静态变量在编译阶段就分配了空间，对象还没创建时就已经分配了空间，放到全局静态区。

* 静态成员变量
  * 最好是类内声明，类外初始化（以免类名访问静态成员访问不到）
  * 无论公有，私有，静态成员都可以在类外定义，但私有成员仍有访问权限
  * 非静态成员类外不能初始化
  * 静态成员数据是共享的。
* 静态成员函数
  * 静态成员函数可以直接访问静态成员变量，不能直接访问普通成员变量，但可以通过参数传递的方式访问
  * 普通成员函数可以访问普通成员变量，也可以访问静态成员变量
  * 静态成员函数没有this指针。非静态数据成员为对象单独维护，但静态成员函数为共享函数，无法区分是哪个对象，因此不能直接访问普通变量成员，也没有this指针。

## 初始化列表的好处和使用条件

* 初始化列表的使用条件
  * const类型的数据
  * 引用类型的数据
* 好处
  * 初始化是直接初始化成员
  * 赋值是初始化再赋值

## 能否通过初始化列表初始化静态成员变量

不能，静态成员变量最好类内声明，类外初始化.静态成员是单独存储的，并不是对象的组成部分。如果在类的内部进行定义，在建立多个对象时会多次声明和定义该变量的存储位置。在名字空间和作用域相同的情况下会导致重名的问题。

## [友元全局函数、友元类、友元成员函数](https://www.cnblogs.com/qinguoyi/p/10254263.html)

友元主要是为了访问类中的私有成员（包括属性和方法），会破坏C++的封装性，尽量不使用

* 友元全局函数
  * 友元函数声明可以在类中的任何地方，一般放在类定义的开始或结尾
  * 一个函数可以是多个类的友元函数，只需要在各个类中分别声明
  * 友元函数在类内声明，类外定义，定义和使用时不需加作用域和类名，与普通函数无异。
* 友元类
  * 友元不可继承
  * 友元是单向的，类A是类B的友元类，但类B不一定是类A的
  * 友元不具有传递性，类A是类B的友元类，类B是类C的友元类，但类A不一定是类C的友元类。

* 友元成员函数
  * 使类B中的成员函数成为类A的友元函数，这样类B的该成员函数就可以访问类A的所有成员

## 运算符重载及++重载实现

### 运算符重载基本属性

* 运算符重载的目的是扩展C++中提供的运算符的适用范围，使之能作用于对象，或自定义的数据类型
* 运算符重载的实质是函数重载，可以重载为普通成员函数，也可以重载为成员函数
* 运算符重载也是多态的一种，和函数重载称为静态多态，表示函数地址早绑定，在编译阶段就确定好了地址

### 运算符重载总结

* 重载运算符()，[] ，->， =的时候，运算符重载函数必须声明为类的成员函数
* 重载运算符<<，>>的时候，运算符只能通过全局函数配合友元函数进行重载
* 不要重载&&和||运算符，因为无法实现短路原则。

### i++和++i实现

C++内置类型的后置++返回的是变量的拷贝，也就是不可修改的值；前置++返回的是变量的引用，因此可以作为修改的左值。即++（++a）或（++a）++都可以，但++（a++）不可以，（C++默认必须修改a的值，如果不修改则报错）。

```C++
//++i
int&  int::operator++()
{
    *this +=1；
    return *this；
}

//i++，注意后置++有占位参数以区分跟前置++不同
const int  int::operator++(int)
{
    int oldValue = *this；
    ++（*this）；
    return oldValue；
}
```

## [继承方式、对象模型、同名处理](https://www.cnblogs.com/qinguoyi/p/10277350.html)

继承主要是为了减少代码的重复内容，解决代码复用问题。通过抽象出一个基类（父类），将重复代码写到基类中，在派生类（子类）中实现不同的方法。

### 继承方式

* 公有继承：保持父类中的访问属性
* 私有继承：将父类中的所有访问属性改为private
* 保护继承：除父类中的私有属性，其他改为保护属性

### 继承的对象模型

* 子类中会继承父类的私有成员，只是被编译器隐藏起来了，无法访问到，通过sizeof(子类class)可以检查出。
* 子类创建对象时，先调用父类的构造函数，然后再调用自身的构造，析构顺序与构造顺序相反
  * 由于继承中父类和子类的构造、析构顺序原因，当父类中只提供了有参构造（默认构造等函数会被隐藏），而子类仅仅调用默认构造时，会因为子类创建对象时无法调用父类构造函数而报错，这里可以让子类利用初始化列表来显式调用父类有参构造函数来进行父类构造，然后进行子类构造。
* 子类会继承父类的成员属性和成员函数，但子类不会继承父类构造函数和析构函数

### 继承中的同名处理

* 父类和子类**成员属性**同名，用子类声明对象调用子类属性，若想调用父类成员，则加上父类的作用域
* 父类和子类**成员函数**同名，子类函数不会覆盖父类的成员，只是隐藏起来，用子类声明对象调用子类成员函数，若想调用父类函数（包括重载），则加上父类的作用域
* 若子类中没有与父类同名的成员函数，子类声明对象后，可以直接调用父类成员函数。

## [多继承和菱形继承](https://www.cnblogs.com/qinguoyi/p/10277350.html)

### 多继承

多继承会产生二义性的问题。如果继承的多个父类中有同名的成员属性和成员函数，在子类调用时，需要指定作用域从而确定父类。

### 菱形继承

两个子类继承于同一个父类，同时又有另外一个类多继承于两个子类，这种继承称为菱形继承。比如羊和驼继承于动物类，同时羊驼继承于羊和驼。

#### 菱形继承会产生问题

* **浪费空间。**羊驼继承了两份动物类中的某些数据和函数，但只需要一份即可
* **二义性。从不同途径继承来的同名的数据成员在内存中有不同的拷贝造成数据不一致问题。** 羊驼调用数据和函数时，会出现二义性，通过sheep类得到一个age，通过carmel类得到一个age，两个数据不会相互影响，相互修改，导致同一份数据不一致。

#### 解决菱形继承的问题

使用虚继承，在**继承方式前加virtual**，这样的话羊驼可以直接访问m_Age，不用添加作用域，且这样操作的是共享的一份数据

```C++
class Animal{
public:
    int m_Age;
};
class Sheep:virtual public Animal{
    int m_sheep;
};
class Camel :virtual public Animal{
    int m_camel;
};

class Son :public Sheep, public Camel{
    int m_son
};
void test01(){
    Son son;
    son.m_Age = 10;
    cout << sizeof(Animal) << endl; //m_Age
    cout << sizeof(Sheep) << endl;  //sheep-Vbptr,m_sheep,m_Age
    cout << sizeof(Camel) << endl;  //camel-Vbptr,m_camel,m_Age
    cout << sizeof(Son) << endl;    //sheep-Vbptr,m_sheep,camel-Vbptr,m_camel,m_son,m_Age
}
```

<div align=center><img width="640" height="450" src="https://github.com/twomonkeyclub/BackEnd/blob/master/%E5%9F%BA%E7%A1%80%E8%AF%AD%E8%A8%80/utils/%E5%A4%9A%E8%99%9A%E7%BB%A7%E6%89%BF.png"/></div>

> * **特别注意：**此时son没有自己的虚基类表和虚基类指针，只是继承了sheep和camel的虚基类指针和虚基类表，只是修改了两个虚基类表中的值，修改为当前类中，如何通过继承的虚基类指针查找虚基类数据
> * Son继承Sheep父类，父类中有虚基类指针vbptr(virtual base pointer)，对象结构类似结构体，首元素是虚基类指针，其余为自身数据（不包括静态成员和成员函数）
> * Sheep的虚指针指向下面Sheep的虚基类表vbtale@Sheep(virtual base table)，虚基类表是一个整型数组，数组第二个元素值为20，即Sheep的虚指针地址偏移20指向Animal的m_Age地址。Camel父类同理，因此，类中只有一个m_Age元素。
> * Son中包含了两个指针和四个int类型，所以大小为24。

```C++
class Animal{
public:
    int m_Age;
};
class Sheep:virtual public Animal{
    int m_sheep;
};
class Camel :virtual public Animal{
    int m_camel;
};

class Son :virtual public Sheep, virtual public Camel{
    int m_son
};
void test01(){
    Son son;
    son.m_Age = 10;
    cout << sizeof(Animal) << endl; //m_Age
    cout << sizeof(Sheep) << endl;  //sheep-Vbptr,m_sheep,m_Age
    cout << sizeof(Camel) << endl;  //camel-Vbptr,m_camel,m_Age
    cout << sizeof(Son) << endl;    //son-vbptr,m_son,m_Age,sheep-Vbptr,m_sheep,camel-Vbptr,m_camel,
}
```

<div align=center><img width="640" height="600" src="https://github.com/twomonkeyclub/BackEnd/blob/master/%E5%9F%BA%E7%A1%80%E8%AF%AD%E8%A8%80/utils/%E8%8F%B1%E5%BD%A2%E7%BB%A7%E6%89%BF.png"/></div>

> * 注意跟上面的区别，一个是son类中的元素顺序，一个是son类有了自己的虚基类指针和虚基类表

* 虚继承
  * 一般通过虚基类指针和虚基类表实现，将共同基类设置为虚基类
  * **每个虚继承的子类（虚基类本身没有）**都有一个虚基类指针（占用一个指针的存储空间）和虚基类表（不占用类对象的存储空间），**虚基类指针属于对象，虚基类表属于类**
  * 当虚继承的子类被当做父类继承时，虚基类指针也会被继承。
  * 虚表中只记录了虚基类数据在派生类对象中与派生类对象首地址(虚基类指针)之间的偏移量,以此来访问虚基类数据
  * 虚继承不用像普通多继承那样维持着公共基类（虚基类）的两份同样的拷贝，节省了存储空间。
  * 虚基类表本质是一个**整型数组**

## 静态函数可以是虚函数吗

不可以，因为虚函数属于对象，不属于类，静态函数属于类

## 类型兼容性原则 为什么会有多态

类型兼容规则是指在需要基类对象的任何地方，都可以使用公有派生类的对象来替代,如使用子类对象可以直接赋值给父类对象或子类对象可以直接初始化父类对象时，**对于同样的一条语句，不管传入子类还是父类对象，都是调用的父类函数，但我们想实现的是同样的一条语句，传入不同的对象，调用不同的函数**.

```C++
class Animal{
public:
 void speak(){
  cout << "Animal speak" << endl;
 }
};

class Sheep :public Animal{
public:
 void speak(){ //重定义，子类重新定义父类中有相同名称的非虚函数 
  cout << "Sheep speak" << endl;
 }
};

void doSpeak(Animal &animal){
 animal.speak();
}

//想通过父类引用指向子类对象
void test01(){
 Sheep sheep;
 doSpeak(sheep); //Animal speak;
 sheep.speak();  //sheep speak
 sheep.Animal::speak();  //Animal speak; //继承中的重定义可以通过作用域
}
```

但我们想**传入子类对象调用子类函数，传入父类对象调用父类函数**，即同样的调用语句有多种不同的表现形态，这样就出现了**多态**

## 重载、覆盖、重写

* 重载(overload)：是函数名相同，参数列表不同。重载只是在同一个类的内部存在，但是不能靠返回类型来判断
* 覆盖(override)：子类重新定义父类中有相同名称和参数的虚函数。两者的函数特征相同。
  * 被重写的函数不能是static的。必须是virtual的
  * 重写函数必须有相同的类型，名称和参数列表
  * 重写函数的访问权限可以不同。尽管virtual是private的，子类中重写改写为public,protected也是可以的。
* 重写(overwrite)：也叫做隐藏。子类重新定义父类中有相同名称的非虚函数 ( 参数列表可以不同 ) 。如果一个类，存在和父类相同的函数，那么，这个类将会隐藏其父类的方法，除非你在调用的时候，强制转换为父类类型或加上父类作用域

## 多态实现的基础
>
> * 继承
> * 虚函数覆盖
> * 父类指针或引用指向子类对象访问虚函数

```C++
class Animal{
public:
 virtual  void speak(){ //在父类中声明虚函数，可以实现多态，动态联编
  cout << "Animal speak" << endl;
 }
 int m_age = 0;
};

class Sheep :public Animal{
public:
 void speak(){ //发生多态时，子类对父类中的成员函数进行重写，virtual可写可不写
  cout << "Sheep speak" << endl;
 }
 int m_age = 1;
};

void doSpeak(Animal &animal){
 animal.speak();
}

void test01(){
    //传入子类对象调用子类成员函数
 Sheep sheep;
 doSpeak(sheep); //sheep speak;
 
    //子类对象直接调用子类成员函数
 sheep.speak();  //sheep speak;
 
 //子类对象通过作用域调用父类成员函数
    sheep.Animal::speak();  //animal speak;
    
    //基类成员不能转换为子类成员，即不能向下转换
 //Animal *animal0 = new Animal();
 //Sheep * sheep0 = animal0;
 //sheep0->speak();

    //同样不能向下转换
 //Animal animal0;
 //Sheep sheep0 = animal0;

    //父类指针指向子类对象
 Sheep *sheep1 = new Sheep();
 Animal *animal1 = sheep1;
 animal1->speak(); //sheep speak;
 
 //父类引用指向子类对象
 Sheep sheep2;
 Animal &animal2 = sheep2;
 animal2.speak();    //sheep speak;
 
 //子类对象直接赋值给父类对象，不符合多态条件，符合类型兼容性原则
 Sheep sheep0;
 Animal animal0 = sheep0;
 animal0.speak();    //animal speak;
}
```

## 静态多态和动态多态
>
> * 静态多态（运算符重载、函数重载）
> * 动态多态（继承、虚函数）

两者主要的区别：函数地址是早绑定（静态联编）还是晚绑定（动态联编）。即，在编译阶段确定好地址还是在运行时才确定地址。

## 虚函数指针和虚函数表
>
> * 前提发生了多态，每个类中都有虚函数表，最开始的父类创建虚函数表，后面的子类继承父类的虚函数表，然后对虚函数重写
> * 虚函数重写（覆盖）的实质就是重写父类虚函数表中的父类虚函数地址；
> * 实现多态的流程：虚函数指针->虚函数表->函数指针->入口地址，**虚函数表（vftable）属于类**，或者说这个类的所有对象共享一个虚函数表；**虚函数指针（vfptr）属于单个对象**。
> * 在程序调用时，先创建对象，编译器在对象的内存结构头部添加一个虚函数指针，进行动态绑定，虚函数指针指向对象所属类的虚函数表。
> * 虚函数表是一个指针数组，其元素是虚函数的指针，每个元素对应一个函数的指针。如果子类对父类中的一个或多个虚函数进行重写，子类的虚函数表中的元素顺序，会按照父类中的虚函数顺序存储，之后才是自己类的函数顺序。
> * 编译器根本不会去区分，传进来的是子类对象还是父类对象，而是关心调用的函数是否为虚函数。如果是虚函数，就根据不同对象的vptr指针找属于自己的函数。父类对象和子类对象都有vfptr指针，传入对象不同，编译器会根据vfptr指针，到属于自己虚函数表中找自己的函数。即：vptr--->虚函数表------>函数的入口地址，从而实现了迟绑定(在运行的时候，才会去判断)。

## [函数指针与指针函数](https://www.cnblogs.com/qinguoyi/p/10198019.html)

* 指针函数`int* f(int x, int y)`本质是函数，返回值为指针，函数指针`int (*f)(int x)`本质是指针，指向函数的指针

* 通常我们可以将指针指向某类型的变量，称为类型指针（如，整型指针）。若将一个指针指向函数，则称为函数指针。

* 函数名代表函数的入口地址，同样的，我们可以通过根据该地址进行函数调用，而非直接调用函数名。

```C++
void test001(){
    printf("hello, world");
}

int main(){
    void(*myfunc)() = test001;//将函数写成函数指针
    myfunc(); //调用函数指针 hello world
}
```

test001的函数名与myfunc函数指针都是一样的，即都是函数指针。test001函数名是一个函数指针常量，而myfunc是一个函数指针变量，这是它们的关系。

* 函数指针多用于回调函数，回调函数最大的优势在于灵活操作，可以实现用户定制的函数，降低耦合性，实现多样性，如STL中

## 怎么理解多态和虚函数

* 多态的实现主要分为静态多态和动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。

* 举个例子：一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数

虚函数的实现：在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。

## 构造函数能否实现多态/虚函数指针什么时候初始化

两个问题本质是一样的，构造函数不能实现多态

* 对象在创建时,由编译器对VPTR指针进行初始化，只有当对象的构造完全结束后VPTR的指向才最终确定。

* 子类中虚函数指针的初始化过程
当定义一个子类对象的时候比较麻烦，因为构造子类对象的时候会首先调用父类的构造函数然后再调用子类的构造函数。当调用父类的构造函数的时候，此时会创建Vptr指针，该指针会指向父类的虚函数表；然后再调用子类的构造函数，子类继承父类的虚函数指针，此时Vptr又被赋值指向子类的虚函数表。

## 构造函数能否是虚函数

不能，因为在调用构造函数时，虚表指针并没有在对象的内存空间中，必须要构造函数调用完成后才会形成虚表指针

## 抽象类和纯虚函数

在程序设计中，如果仅仅为了设计一些虚函数接口，打算在子类中对其进行重写，那么不需要在父类中对虚函数的函数体提供无意义的代码，可以通过纯虚函数满足需求。

* 纯虚函数的语法格式：`virtual 返回值类型 函数名 () = 0;`只需要将函数体完全替换为 =0即可，**纯虚函数必须在子类中进行实现**，在子类外实现是无效的。

* 注意
  * 如果父类中出现了一个纯虚函数，则这个类变为了抽象类，抽象类不可实例对象
  * 如果父类为抽象类，子类继承父类后，必须实现父类所有的纯虚函数，否则子类也为抽象类，也无法实例对象**但纯虚析构函数例外，因为子类不会继承父类的析构函数**

## 虚析构和纯虚析构
>
> * 仅仅发生继承时，创建子类对象后销毁，函数调用流程为：父类构造函数->子类构造函数->子类析构函数->父类析构函数；
> * 当发生多态时（父类指针或引用指向子类对象），通过父类指针在堆上创建子类对象，然后销毁，调用流程为：父类构造函数->子类构造函数->父类析构函数，不会调用子类析构函数，因此子类中会出现内存泄漏问题。

解决方法：将父类中的析构函数设置为虚函数，设置后会先调用子类析构函数，再调用父类析构函数

* 纯虚析构
  * 纯虚析构需要类内声明，类外实现
  * 纯虚析构也是虚函数，该类也为抽象类
  * 子类不会继承父类的析构函数，当父类纯虚析构没有实现时，子类不是抽象类，可以创建创建对象。

## 为什么析构函数必须是虚函数

因为当发生多态时，父类指针在堆上创建子类对象，销毁时会内存泄漏

## 为什么C++默认的析构函数不是虚函数

因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存

## 类模板和函数模板

通过template<class T>或template<typename T>实现，主要用于数据的类型参数化，简化代码，有类模板和函数模板，函数模板是用于生成函数的，类模板则是用于生成类的

* 类模板和函数模板定义
>
> * template声明下面是函数定义，则为函数模板，否则为类模板。
> * 注意：每个函数模板前必须有且仅有一个template声明，不允许多个template声明后只有一个函数模板，也不允许一个template声明后有多个函数模板(类模板同理)。

* 类模板与函数模板的区别
  * 类模板不支持自动类型推导
  * 数据类型可以有默认参数.

---

## c++编译底层

# C/C++编译底层

> * [C++内存管理](#C++内存管理)
> * [LINUX进程区分段及存储数据](#LINUX进程区分段及存储数据)
> * [GCC编译流程](#GCC编译流程)
> * [动态库静态库区别及LINUX加载库](#动态库静态库区别及GCC加载库)
> * [extern C的结果和CPP编译的区别](#extern-C的结果和CPP编译的区别)
> * [重载的底层原理](#重载的底层原理)
> * [编译性语言和解释性语言的本质区别和优缺点](#编译性语言和解释性语言的本质区别和优缺点)

## C++内存管理
>
> * **栈** 存储函数的返回地址、参数、局部变量、返回值，从高地址向低地址增长
> * **堆** malloc/free开辟内存的空间，从低地址向高地址增长
> * **自由存储区** new/delete开辟内存空间
> * **数据区**
数据区包含全局/静态存储区和常量存储区，存储已初始化的全局变量和静态变量、未初始化的全局变量和静态变量及字符串常量
> * **代码区** 存储程序的机器代码和程序指令

## LINUX进程区分段及存储数据

Linux的每个进程都有各自独立的4G逻辑地址，其中0~3G是用户态空间，3~4G是内核空间，不同进程相同的逻辑地址会映射到不同的物理地址中。
逻辑地址分段如下，自下而上：
>
> * 代码段。分为只读存储区和代码区，存放字符串是常量和程序机器代码和指令
> * 数据段。存储已初始化的全局变量和静态变量。
> * bss段。存储未初始化的全局变量和静态变量，及初始化为0的全局变量和静态变量
> * 堆。 当进程未调用malloc时是没有堆段的，malloc/free开辟的内存空间，向上生长
> * 映射区。存储动态链接库以及调用mmap函数进行的文件映射
> * 栈。存储函数的返回地址、参数、局部变量、返回值，向下生长。

## GCC编译流程

* 预处理阶段：hello.c -- "gcc -E预处理，头文件展开，宏替换" --> hello.i
* 编译阶段：hello.i -- "gcc -s生成汇编文件" --> hello.s
* 汇编阶段：hello.s -- "gcc -c生成二进制文件" --> hello.o
* 链接阶段：hello.o -- "调用ld进行链接" --> a.out

## 动态库静态库区别及GCC加载库

静态库
>
> * 编译时期链接
> * 浪费空间和资源，如果多个程序链接了同一个库，则每一个生成的可执行文件就都会有一个库的副本，必然会浪费系统空间。
> * 若静态库需修改，需重新编译所有链接该库的程序

动态库
>
> * 运行时链接
> * 运行时被链接，故程序的运行速度稍慢
> * 动态库是在程序运行时被链接的，所以磁盘上只须保留一份副本，因此节约了磁盘空间。如果发现了bug或要升级也很简单，只要用新的库把原来的替换掉即可

GCC编译加载静态库

* 将所有的.c文件编译成.o目标文件
  * `gcc -c add.c` 生成add.o
  * `gcc -c max.c` 生成max.o
* 对生成的.o目标文件打包生成静态库
  * `ar crv libfoo.a add.o max.o //libfoo.a是库的名字`
  * ar:做库的命令
  * c:创建库
  * r:将方法添加到库里
  * v：显示过程，可以不要

* 使用静态库
  * `gcc -o main main.c -static -L. -lfoo //这里写的foo是去掉前后缀后库的名字`
  * -L：指定路径 .代表当前路径
  * -l：指定库名

GCC编译加载动态库

* 对生成的.o文件处理生成共享库，共享库的名字为libfoo.so
  * `gcc -shared -fPIC -o libfoo.so add.o max.o`
  * -shared 表示输出结果是共享库类型的
  * -fPIC 表示使用地址无关代码（Position Independent Code）技术来生产输出文件

* 库的使用
  * `cp libfoo.so /usr/lib //将库拷贝到系统库路径下`（不推荐）
  * export更改LD_LIBRARY_PATH当前终端的环境变量
  * 修改/etc/ld.so.conf文件，加入库文件所在目录的路径，然后
运行ldconfig 目录名字，该命令会重建/etc/ld.so.cache文件即可

  * 上面三种选一个即可`gcc -o main main.c -lfoo`

## [extern-C的结果和CPP编译的区别](https://www.cnblogs.com/qingergege/p/7478864.html)

* 一个C语言文件p.c

```C
#include <stdio.h>
void print(int a,int b)
{
       printf("这里调用的是C语言的函数:%d,%d\n",a,b);
}
```

* 一个头文件p.h

```C++
#ifndef _P_H
#define _P_H

void print(int a,int b);

#endif
```

* C++文件调用C函数

```C++
#include <iostream>
using namespace std;
#include "p.h"
int main()
{
       cout<<"现在调用C语言函数\n";
       print(3,4);
       return 0;
}
```

* 编译后链接出错：main.cpp对print(int, int)未定义的引用。
* 原因分析
  * p.c我们使用的是C语言的编译器gcc进行编译的，其中的函数print编译之后，在符号表中的名字为 _print
  * 我们链接的时候采用的是g++进行链接，也就是C++链接方式，程序在运行到调用print函数的代码时，会在符号表中寻找_print_int_int（是按照C++的链接方法来寻找的，所以是找_print_int_int而不是找_print）的名字，发现找不到，所以会t提示“未定义的引用”
  * 此时如果我们在对print的声明中加入 extern “C” ，这个时候，g++编译器就会按照C语言的链接方式进行寻找，也就是在符号表中寻找_print，这个时候是可以找到的，是不会报错的。

* 总结
  * 编译后底层解析的符号不同，C语言是_print，C++是_print_int_int

## [重载的底层原理](https://blog.csdn.net/fantian_/article/details/80719144)

根据上面的编译分析，可以知道C语言没有重载，只有C++才有函数重载，因为函数重载通过参数列表的不同来实现。

* C语言没有重载

```C++
"int __cdecl Add(int,int)" (?Add@@YAHHH@Z)
"double __cdecl Add(double,double)" (?Add@@YANNN@Z）
"long __cdecl Add(long,long)" (?Add@@YAJJJ@Z)
```

在C语言中被解析为_Add，三个一样，所以不能进行区分，因此C语言不支持函数重载

* C++重载
底层的重命名机制将Add函数根据参数的个数，参数的类型，返回值的类型都做了重新命名。那么借助函数重载，一个函数就有多种命名机制。 _Add_int_int，_Add_long_long，_Add_double_double

* C++中可以通过在函数声明前加 extern "C" 将一个函数按照 C 语言的风格来进行编译。

## [编译性语言和解释性语言的本质区别和优缺点](https://blog.csdn.net/u014647208/article/details/78329187)

* 根本区别
  * 计算机不能直接的理解高级语言，只能直接理解机器语言，所以必须要把高级语言翻译成机器语言，计算机才能执行高级语言的编写的程序。翻译的方式有两种，一个是编译，一个是解释。**两种方式只是翻译的时间不同**。
  * 解释性语言不用编译，在运行时翻译
  * 编译性语言是编译的时候直接编译成机器可以执行的语言，编译和运行是分开的，但是不能跨平台。比如exe文件，以后要运行的话就不用重新编译了，直接使用编译的结果就行了（exe文件），因为翻译只做了一次，运行的时不要翻译，所以编译型语言的程序执行效率高

* 编译性语言的优缺点
  * 优点
    * 运行速度快，代码效率高，编译后程序不可以修改，保密性好
  * 缺点
    * 代码需要经过编译方可运行，可移植性差，只能在兼容的操作系统上运行。
* 解释性语言的优缺点
  * 优点
    * 可移植性好，只要有解释环境，可以在不同的操作系统上运行。
  * 缺点
    * 运行需要解释环境，运行起来比编译的要慢，占用的资源也要多一些，代码效率低，代码修改后就可以运行，不需要编译过程

---

## c++智能指针

# C++补充

> * [构造函数可以抛出异常吗，有什么问题？](#构造函数可以抛出异常吗有什么问题)
> * [初始化列表的异常怎么捕获？](#初始化列表的异常怎么捕获)
> * [析构函数可以抛出异常吗，有什么问题？](#析构函数可以抛出异常吗有什么问题)
> * [析构函数如何处理异常](#析构函数如何处理异常)
> * [智能指针](#智能指针)
> * [内存泄漏](#内存泄漏)
> * [野指针](#野指针)
> * [强制转换](#强制转换)
> * [RTTI](#RTTI)
> * [RAII](#RAII)
> * [CPP11新特性](#CPP11新特性)
> * [仿函数](#仿函数)

## [构造函数可以抛出异常吗，有什么问题？](https://www.cnblogs.com/qinguoyi/p/10304882.html)

构造函数中应该避免抛出异常。
>
> * 构造函数中抛出异常后，对象的析构函数将不会被执行
> * 构造函数抛出异常时，本应该在析构函数中被delete的对象没有被delete，会导致内存泄露
> * 当对象发生部分构造时，已经构造完毕的子对象（非动态分配）将会逆序地被析构。

## 初始化列表的异常怎么捕获？
>
> * 初始化列表构造，当初始化列表出现异常时，程序还未进入函数体，因此函数体中的try-catch不能执行，catch也无法处理异常。可以通过函数try块解决该问题。
> * 函数try块中的try出现在表示构造函数初始值列表的冒号以及表示构造函数体的花括号之前，与这个try关联的catch既能处理构造函数体抛出的异常，也能处理成员初始化列表抛出的异常。

## 析构函数可以抛出异常吗，有什么问题？

析构函数不应该抛出异常
>
> * **其他正常，仅析构函数异常**。 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。
> * **其他异常，且析构函数异常**。 通常异常发生时，c++的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。

## 析构函数如何处理异常？
>
> * 若析构函数抛出异常，调用std::abort()来终止程序
> * 在析构函数中catch捕获异常并作处理，吞下异常；
> * 如果客户需要对某个操作函数运次期间抛出的异常做出反应，class应该提供普通函数执行该操作，而非在析构函数中。

## [智能指针](https://www.cnblogs.com/TianFang/archive/2008/09/20/1294590.html)

智能指针有shared_ptr,weak_ptr,unique_ptr，[参考](https://www.cnblogs.com/wxquare/p/4759020.html)，使用普通指针，容易造成堆内存泄露（忘记释放），二次释放，程序发生异常时内存泄露等问题等，使用智能指针能更好的管理堆内存。

* shared_ptr核心要理解引用计数，什么时候销毁底层指针，还有赋值，拷贝构造时候的引用计数的变化，析构的时候要判断底层指针的引用计数为0了才能真正释放底层指针的内存
  * 不能将指针直接赋值给一个智能指针，一个是类，一个是指针。例如`std::shared_ptr<int> p4 = new int(1);`
  * 可以`std::shared_ptr<int>p4(new int(1));`
  * 拷贝使得对象的引用计数增加1，赋值使得原对象引用计数减1，当计数为0时，自动释放内存。后来指向的对象引用计数加1，指向后来的对象
  * 赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数

* shared_ptr创建后是栈上的对象，当出作用域后，每个对象会自动调用析构函数，如上所述，new int(1)会生成一个指针，此时将其传参数给shared_ptr,由shared_ptr对其进行管理，shared_ptr虽然是对象，但其有指针的特性，通过重载运算符*和->实现指针的特性来访问被管理的指针。

* shared_ptr是可以共享所有权的智能指针
  * shared_ptr的管理机制其实并不复杂，就是对所管理的对象（这里的对象本质是被管理的指针new int(1)，并不是类和对象中的对象）进行了引用计数，当新增一个shared_ptr对该对象进行管理时，就将该对象的引用计数加一；减少一个shared_ptr对该对象进行管理时，就将该对象的引用计数减一，如果该对象的引用计数为0的时候，说明没有任何指针对其管理，才调用delete释放其所占的内存。
  * 对shared_ptr进行初始化时不能将一个普通指针直接赋值给智能指针，因为一个是指针，一个是类，可以通过make_shared函数或者通过构造函数传入普通指针
  * 不要把一个原生指针给多个shared_ptr，不要把this指针交给智能指针管理，这样会重复释放
  * shared_ptr之间的资源共享是通过shared_ptr智能指针拷贝、赋值实现的，因为这样可以引起计数器的更新；而如果直接通过原生指针来初始化，就会导致m_sp和p都根本不知道对方的存在，然而却两者都管理同一块地方

```C++
int* ptr = new int;
shared_ptr<int> p1(ptr);
shared_ptr<int> p2(ptr); //这样不会导致更新，两者不知对方存在
shared_ptr<int> p3(p1);//这样才会导致计数器更新
```

* shared_ptr循环引用导致内存泄漏，引出weak_ptr
  * 循环引用是两个强引用（shared_ptr）互相引用，使得两者的引用计数无法为0，进而无法释放，此时将循环引用的一方变为weak_ptr即可。

```C++
template <typename T>
class Node
{
public:
    Node(const T& value)
        :_pPre(NULL)
        , _pNext(NULL)
        , _value(value)
    {
        cout << "Node()" << endl;
    }
    ~Node()
    {
        cout << "~Node()" << endl;
        cout << "this:" << this << endl;
    }

    shared_ptr<Node<T>> _pPre;
    shared_ptr<Node<T>> _pNext;
    T _value;
};

void Funtest()
{
    shared_ptr<Node<int>> sp1(new Node<int>(1));
    shared_ptr<Node<int>> sp2(new Node<int>(2));

    cout << "sp1.use_count:" << sp1.use_count() << endl;
    cout << "sp2.use_count:" << sp2.use_count() << endl;

    sp1->_pNext = sp2;
    sp2->_pPre = sp1;

    cout << "sp1.use_count:" << sp1.use_count() << endl;
    cout << "sp2.use_count:" << sp2.use_count() << endl;
}
int main()
{
    Funtest();
    system("pause");
    return 0;
}
```

上述情况造成了一个僵局，那就是析构对象时先析构sp2,可是由于sp2的空间sp1还在使用中，所以sp2.use_count减减之后为1，不释放，sp1也是相同的道理，由于sp1的空间sp2还在使用中，所以sp1.use_count减减之后为1，也不释放。sp1等着sp2先释放，sp2等着sp1先释放,二者互不相让，导致最终都没能释放，内存泄漏。

* **弱引用（weak_ptr）并不修改该对象的引用计数**，weak_ptr必须从一个share_ptr或另一个weak_ptr转换而来，这也说明，进行该对象的内存管理的是那个强引用的share_ptr,weak_ptr只是提供了对管理对象的一个访问手段这意味这弱引用它并不对对象的内存进行管理。在功能上类似于普通指针，然而一个比较大的区别是，弱引用能检测到所管理的对象是否已经被释放，从而避免访问非法内存

```C++
weak_ptr<Node<T>> _pPre;
weak_ptr<Node<T>> _pNext;
```

expired()用于检测所管理的对象是否已经释放；lock()用于获取所管理的对象的强引用指针，不能直接访问弱引用，需要将其先通过lock转换为强引用再访问

* unique_ptr
    unique_ptr实现独占式拥有或严格拥有概念，保证同一时间内只有一个智能指针可以指向该对象

## 内存泄漏

当一个对象已经不需要再使用本该被回收时，另外一个正在使用的对象持有它的引用从而导致它不能被回收，这导致本该被回收的对象不能被回收而停留在堆内存中，这就产生了内存泄漏。

## 野指针

野指针指向一个已删除的对象或 申请访问受限内存区域的指针。

* 原因
  * 指针变量未初始化
  * 指针释放未置空
  * 指针操作超出作用域。返回指向栈内存的指针或引用，因为栈内存在函数结束时会被释放。

## 强制转换

C++中强制转换为static_cast, dynamic_cast,const_cast, reinterpret_cast

* static_cast
  * 完成基础数据类型；同一个继承体系中类型的转换；任意类型与空指针类型void* 之间的转换，不能用于普通指针的转换（void空指针除外）
* dynamic_cast
  * 动态类型转换，用于实现RTTI。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常bad_cast
* const_cast
  * 用于删除 const、volatile特性
* reinterpret_cast
  * 几乎什么都可以转,不能丢掉 const、volatile特性

## RTTI

运行时类型检查，在C++层面主要体现在dynamic_cast和typeid
>
> * dynamic_cast
    动态类型转换
> * typeid
    typeid 运算符允许在运行时确定对象的类型，获取对象的实际类型

## RAII

RAII全称是“Resource Acquisition is Initialization”，直译过来是“资源获取即初始化”.

* 在构造函数中申请分配资源，在析构函数中释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定。
* RAII的核心思想是将资源或者状态与对象的生命周期绑定，通过C++的语言机制，实现资源和状态的安全管理,智能指针是RAII最好的例子

## CPP11新特性

* nullptr常量
  * C++中NULL仅仅是`define NULL 0`的一个宏定义，因此，有时候会产生歧义
    * 比如f（char*）和f（int），参数传NULL的话到底该调用哪个？
    * 事实上，在VS下测试这样的函数重载会优先调用f（int），但是f（char *）也是正确的，因此C++引入nullptr来避免这个问题
  * nullptr是一个空指针，可以被转换成其他任意指针的类型
* auto类型指示符
  * 让编译器替我们去分析表达式所属的类型，直接推导
  * 尤其是STL中map的迭代器这种很长的类型，适合用auto
* decltype类型指示符
  * 从表达式的类型推断出要定义的变量的类型，跟表达式的类型也就是参数类型紧密相关
  * `delctype (f()) sum = x;` 并不实际调用函数f()，只是使用f()的返回值当做sum的类型
  * `delctype (i) sum = x;`和`delctype ((i)) sum = x;` 其中i为int类型，前面的为int类型，后面的为int&引用
* 范围for语句
  * 多与auto配合使用

```C++
string str("somthing");
for(auto i:str) //对于str中的每个字符，i类型为char
    cout << c << endl;

for(auto &i:str) //对于若要改变每个字符的值，需要加引用
    cout << c << endl;
```

* 定义双层vector
  * `vector<vector<int>>(m, vector<int>(n, 0))` 创建m行n列的二维数组，全部初始化为0
* [lambda表达式](https://blog.csdn.net/qq_43265890/article/details/83218413)
  * 用于实现匿名函数，匿名函数只有函数体，没有函数名

```C++
[capture list] (params list) mutable exception-> return type {function body};  //1
[capture list] (params list) -> return type {function body};  //1 省略mutable，表示const不可修改
[capture list] (params list) {function body};  //2 省略返回类型，按照函数体返回值决定返回类型
[capture list] {function body};  //3 省略参数列表，无参函数
```

* 参数
  * capture list：捕获外部变量列表
  * params list：形参列表
  * mutable指示符：用来说用是否可以修改捕获的变量
  * exception：异常设定
  * return type：返回类型
  * function body：函数体

```C++
//示例
sort(vec.begin(), vec.end(), [](int a, int b)->bool{return a < b})
```

* 参数捕获方式
  * 值捕获(传参)、引用捕获（传引用）、隐式捕获（传=，函数体直接使用变量））。

* 智能指针
  * shared_ptr
  * weak_ptr
  * unique_ptr
* 右值引用
  * 左值引用，必须引用左值 `int a = 0; int &b = a;`
  * 右值引用可以引用结果 `int && i = 0`

## 仿函数

* 定义
  * 仿函数(functor)又称之为函数对象（function object），其实就是重载了operator()操作符的struct或class，是一个能行使函数功能的类
  * 它使一个类的使用看上去像一个函数，这个类就有了类似函数的行为，就是一个仿函数类。

---

## c++ STL

# STL
>
> * [vector如何扩展内存和释放内存](#vector如何扩展内存和释放内存)
> * [STL中各种容器对比](#各种容器对比)
> * [STL中的swap函数](#STL中的swap函数)
> * [STL中哈希表扩容](#STL中的哈希表扩容)
> * [STL迭代器失效的情况和原因](#STL迭代器失效的情况和原因)
> * [vector删除元素后如何避免当前迭代器会失效](#vector删除元素后如何避免当前迭代器会失效)
> * [vector的iterator和const_iterator和const iterator](#vector的iterator和const_iterator和constiterator)

## [vector如何扩展内存和释放内存](https://www.cnblogs.com/biyeymyhjob/archive/2012/09/12/2674004.html)
>
> * 内存增长
> * [1.5还是2倍扩容](https://blog.csdn.net/dengheCSDN/article/details/78985684)
> * 内存释放

## 各种容器对比

|容器 |底层数据结构|时间复杂度 |有无序 |可不可重复 | 其他|
| :------: | :------: | :------: |:------: |:------: |:------: |
|array  |数组   | 随机读改 O(1)| 无序 |可重复 |支持快速随机访问                                                         |
|vector  |数组   | 随机读改、尾部插入、尾部删除 O(1)、头部插入、头部删除 O(n) |无序 |可重复 |支持快速随机访问                                                         |
|list  |双向链表   |插入、删除 O(1)、随机读改 O(n)        |无序 |可重复 |支持快速增删                                                            |  
|deque  |双端队列   |头尾插入、头尾删除 O(1)         |无序 |可重复 |一个中央控制器 + 多个缓冲区，支持首尾快速增删，支持随机访问                    |
|stack  |deque / list |顶部插入、顶部删除 O(1)         |无序 |可重复 |deque 或 list 封闭头端开口，不用 vector 的原因应该是容量大小有限制，扩容耗时   |
|queue  |deque / list |尾部插入、头部删除 O(1)         |无序 |可重复 |deque 或 list 封闭头端开口，不用 vector 的原因应该是容量大小有限制，扩容耗时   |
|priority_queue   |vector + max - heap |插入、删除 O(log2n)    |有序 |可重复 |vector容器 + heap处理规则                                               |
|set  |红黑树   |插入、删除、查找 O(log2n)         |有序 |不可重复                  |
|multiset |红黑树   |插入、删除、查找 O(log2n)         |有序 |可重复  |                   |
|map  |红黑树   |插入、删除、查找 O(log2n)         |有序 |不可重复|                  |
|multimap |红黑树   |插入、删除、查找 O(log2n)         |有序 |可重复  |  |

## [STL中的swap函数](https://blog.csdn.net/ryfdizuo/article/details/6435847)

* 除了数组，其他容器在交换后本质上是将内存地址进行了交换，而元素本身在内存中的位置是没有变化
* swap在交换的时候并不是完全将2个容器的元素互换，而是交换了2个容器内的内存地址。

## STL中的哈希表扩容

* 这里需要知道STL中的swap底层，其实扩容也是vector扩容
  * 创建一个新桶，该桶是原来桶两倍大最接近的质数(判断n是不是质数的方法：用n除2到sqrt(n)范围内的数) ；
  * 将原来桶里的数通过指针的转换，插入到新桶中(注意STL这里做的很精细，没有直接将数据从旧桶遍历拷贝数据插入到新桶，而是通过指针转换两个桶的地址)
  * 通过swap函数将新桶和旧桶交换，销毁新桶

## vector删除元素后如何避免当前迭代器会失效

删除时，将当前的迭代器存起来

## STL迭代器失效的情况和原因

迭代器失效分三种情况考虑，也是分三种数据结构考虑，分别为数组型，链表型，树型数据结构。

* 数组型数据结构
  * 该数据结构的元素是分配在连续的内存中
  * insert和erase操作，都会使得删除点和插入点之后的元素挪位置，所以，插入点和删除掉之后的迭代器全部失效，也就是说insert(*iter)(或erase(*iter))，然后在iter++，是没有意义的。
  * 解决方法：erase(*iter)的返回值是下一个有效迭代器的值。 `iter = cont.erase(iter);`

```C++
//不要直接在循环条件中写++iter
for (iter = cont.begin(); iter != cont.end();)
{
   (*it)->doSomething();
   if (shouldDelete(*iter))
      iter = cont.erase(iter);  //erase删除元素，返回下一个迭代器
   else
      ++iter;
}
```
 
* 链表型数据结构
  * 对于list型的数据结构，使用了不连续分配的内存
  * 插入不会使得任何迭代器失效
  * 删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器.
  * 解决办法两种，erase(*iter)会返回下一个有效迭代器的值，或者erase(iter++).

* 树形数据结构
  * 使用红黑树来存储数据
  * 插入不会使得任何迭代器失效
  * 删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器.
  * **erase迭代器只是被删元素的迭代器失效，但是返回值为void**，所以要采用erase(iter++)的方式删除迭代器。

**注意** ：经过erase(iter)之后的迭代器完全失效，该迭代器iter不能参与任何运算，包括iter++,*ite

## vector的iterator和const_iterator和const iterator

* 三种的区别
  * iterator，可遍历，可改变所指元素
  * const_iterator，可遍历，不可改变所指元素
  * const iterator，不可遍历，可改变所指元素
* const_iterator转iterator，iterator不能转const_iterator
  * const_iterator 主要是 **在容器被定义成常量、或者非常量容器但不想改变元素值的情况** 下使用的，而且容器被定义成常量之后，它返回的迭代器只能是const_iterator
  * 有些容器成员函数只接受iterator作为参数，而不是const_iterator。那么，如果你只有一const_iterator，而你要在它所指向的容器位置上插入新元素呢？
    * const_iterator转iterator
    * 强制转换的函数会报错，只能通过 `advance(a, distance(a, b));` 其中，distance用于取得两个迭代器之间的距离，advance用于将一个迭代器移动指定的距离
    * 如果a是iterator，b是const_iterator，distance会报错，可以显式的指明distance调用的模板参数类型，从而避免编译器自己得出它们的类型

```C++
typedef deque<int> IntDeque;
typedef IntDeque::iterator iter;
typedef IntDeque::const_iterator ConstIter;
IntDeque d;
ConstIter ci;
Iter i(d.begin());
advance(i,distance<ConstIter>(i,ci)); 
```

---

## socket网络编程

# 网络编程

> * [网络编程的步骤](#网络编程的步骤)
> * [常用API](#常用API)
> * [TCP中的accept和connect和listen的关系](#TCP中的accept和connect和listen的关系)
> * [UDP中的connect](#UDP中的connect)
> * [广播和组播过程](#广播和组播过程)
> * [服务端大量TIMEWAIT或CLOSEWAIT状态](#服务端大量TIMEWAIT或CLOSEWAIT状态)
> * [复位报文段RST](#复位报文段RST)
> * [优雅关闭和半关闭](#优雅关闭和半关闭)
> * [解决TCP粘包](#解决TCP粘包)
> * [select可以判断网络断开吗](#select可以判断网络断开吗)
> * [send和read的阻塞和非阻塞情况](#send和read的阻塞和非阻塞情况)
> * [网络字节序和主机序](#网络字节序和主机序)
> * [IP地址分类及转换](#IP地址分类及转换)
> * [select实现异步connect](#select实现异步connect)
> * [为什么忽略SIGPIPE信号](#为什么忽略SIGPIPE信号)
> * [如何设置非阻塞](#如何设置非阻塞)

## 网络编程步骤

### TCP

* 服务端：socket -> bind -> listen -> accept -> recv/send -> close
  * 创建一个socket，用函数socket()，设置SOCK_STREAM
  * 设置服务器地址和侦听端口，初始化要绑定的网络地址结构
  * 绑定服务器端IP地址、端口等信息到socket上，用函数bind()
  * 设置允许的最大连接数，用函数listen()
  * 接收客户端上来的连接，用函数accept()
  * 收发数据，用函数send()和recv()，或者read()和write()
  * 关闭网络连接close()，需要关闭服务端sock和accept产生的客户端sock文件描述符

* 客户端：socket -> connect -> send/recv -> close
  * 创建一个socket，用函数socket()
  * 设置要连接的对方的IP地址和端口等属性
  * 连接服务器，用函数connect()
  * 收发数据，用函数send()和recv()，或read()和write()
  * 关闭网络连接close()
* 注意
  * INADDR_ANY表示本机任意地址，一般服务器端都可以这样写
  * accept中接收的是客户端的地址，返回对应当前客户端的一个clisock文件描述符，表示当前客户端的tcp连接
  * send和recv中接收的是新建立的客户端的sock地址

### UDP

* 服务端：socket -> bind -> recvfrom/sendto -> close
  * 建立套接字文件描述符，使用函数socket()，设置SOCK_DGRAM
  * 设置服务器地址和侦听端口，初始化要绑定的网络地址结构
  * 绑定侦听端口，使用bind()函数，将套接字文件描述符和一个地址类型变量进行绑定
  * 接收客户端的数据，使用recvfrom()函数接收客户端的网络数据
  * 向客户端发送数据，使用sendto()函数向服务器主机发送数据
  * 关闭套接字，使用close()函数释放资源
* 客户端：socket -> sendto/recvfrom -> close
  * 建立套接字文件描述符，socket()
  * 设置服务器地址和端口，struct sockaddr
  * 向服务器发送数据，sendto()
  * 接收服务器的数据，recvfrom()
  * 关闭套接字，close()
* 注意
  * sendto和recvfrom的第56个参数是sock地址
    * 服务器端的recvfrom和sendto都是cli地址
    * 客户端sendto是服务器端的地址，最后一个参数是指针，recvfrom是新建的from地址，最后一个参数是整型
  * UDP不用listen，accept，因为UDP无连接
  * UDP通过sendto函数完成套接字的地址分配工作
    * 第一阶段：向UDP套接字注册IP和端口号
    * 第二阶段：传输数据
    * 第三阶段：删除UDP套接字中注册的目标地址信息
  * 每次调用sendto函数都重复上述过程，每次都变更地址，因此可以重复利用同一UDP套接字向不同的目标传输数据

## 常用API

sendto、recvfrom保存对端的地址

* sendto
* recvfrom

## [TCP中的accept和connect和listen的关系](https://blog.csdn.net/tennysonsky/article/details/45621341)

### listen

* listen功能
  * listen函数把一个未连接的套接字转换成一个被动套接字，指示内核应接受指向该套接字的连接请求
  * 参数 backlog 的作用是设置内核中连接队列的长度
  * 根据TCP状态转换图，调用listen导致套接字从CLOSED状态转换成LISTEN状态。

* 是否阻塞
  * listen()函数不会阻塞，它将该套接字和套接字对应的连接队列长度告诉 Linux 内核，然后，listen()函数就结束。

* backlog的作用
  * backlog是队列的长度，内核为任何一个给定的监听套接口维护两个队列：
    * 未完成连接队列（incomplete connection queue），每个这样的 SYN 分节对应其中一项：已由某个客户发出并到达服务器，而服务器正在等待完成相应的 TCP 三次握手过程。这些套接口处于 SYN_RCVD 状态。
    * 已完成连接队列（completed connection queue），每个已完成 TCP 三次握手过程的客户对应其中一项。这些套接口处于 ESTABLISHED 状态
  * 当有一个客户端主动连接（connect()），Linux 内核就自动完成TCP 三次握手，该项就从未完成连接队列移到已完成连接队列的队尾，将建立好的链接自动存储到队列中，如此重复
  * backlog 参数历史上被定义为上面两个队列的大小之和，大多数实现默认值为 5

### connect

* connect功能
  * 对于客户端的 connect() 函数，该函数的功能为客户端主动连接服务器，建立连接是通过三次握手，而这个连接的过程是由内核完成，不是这个函数完成的，这个函数的作用仅仅是通知 Linux 内核，让 Linux 内核自动完成 TCP 三次握手连接最后把连接的结果返回给这个函数的返回值（成功连接为0， 失败为-1）。
  * connect之后是三次握手

* 是否阻塞
  * 通常的情况，客户端的connect() 函数默认会一直阻塞，直到三次握手成功或超时失败才返回（正常的情况，这个过程很快完成）。

### accept

* accept功能
  * accept()函数功能是，从处于 established 状态的连接队列头部取出一个已经完成的连接(**三次握手之后**)

* 是否阻塞
  * 如果这个队列没有已经完成的连接，accept()函数就会阻塞，直到取出队列中已完成的用户连接为止。
  * 如果，服务器不能及时调用 accept() 取走队列中已完成的连接，队列满掉后会怎样呢？UNP（《unix网络编程》）告诉我们，服务器的连接队列满掉后，服务器不会对再对建立新连接的syn进行应答，所以客户端的 connect 就会返回 ETIMEDOUT

## UDP中的connect

UDP的connect和TCP的connect完全不同，UDP不会引起三次握手

* 未连接的UDP传输数据
  * 第一阶段：向UDP套接字注册IP和端口号
  * 第二阶段：传输数据
  * 第三阶段：删除UDP套接字中注册的目标地址信息
* 已连接的UDP传输数据
  * 第一阶段：向UDP套接字注册IP和端口号
  * 第二阶段：传输数据
  * 第三阶段：传输数据

* 可以提高传输效率
* 采用connect的UDP发送接受报文可以调用send,write和recv,read操作，也可以调用sendto,recvfrom，此时需要将第五和第六个参数置为NULL或0
* 由已连接的UDP套接口引发的异步错误，返回给他们所在的进程。相反我们说过，未连接UDP套接口不接收任何异步错误给一个UDP套接口，connect后的udp套接口write可以检测发送数据成功与否，直接sendto无法检测

* 多次调用connect拥有一个已连接UDP套接口的进程的作用
  * 指定新的IP地址和端口号
  * 断开套接口

## 广播和组播过程

* 广播
  * 只适用于局域网
  * 只能向同一网络中的主机传输数据，
* 组播
  * 适用于局域网和广域网（internet）

## 服务端大量TIMEWAIT或CLOSEWAIT状态

首先通过TCP的四次挥手过程分析确定两个状态的出现背景。TIMEWAIT是大量tcp短连接导致的，确保对方收到最后发出的ACK，一般为2MSL；CLOSEWAIT是tcp连接不关闭导致的，出现在close()函数之前。

### TIMEWAIT

* 可以通过设置SOCKET选项SO_REUSEADDR来重用处于TIMEWAIT的sock地址，对应于内核中的tcp_tw_reuse，这个参数不是“消除” TIME_WAIT的，而是说当资源不够时，可以重用TIME_WAIT的连接
* 修改ipv4.ip_local_port_range，增大可用端口范围，来承受更多TIME
* 设置SOCK选项SO_LINGER选项，这样会直接消除TIMEWAIT

### CLOSEWAIT

客户端主动关闭，而服务端没有close关闭连接，则服务端产生大量CLOSEWAIT，一般都是业务代码有问题

## 复位报文段RST

* 访问不存在的端口，或服务器端没有启动
* 异常终止连接
  * TCP提供了异常终止连接的方法，给对方发送一个复位报文段
  * 此时对端read会返回-1，显示错误errno:Connection reset by peer
  * 这种错误可以通过shutdown来解决
* 处理半打开连接
  * 当某端崩溃退出，此时对端并不知道，若往对端发送数据，会响应一个RST复位报文段

## [优雅关闭和半关闭](https://www.cnblogs.com/liyulong1982/p/3990740.htm)

### 概念

* 一个文件描述符关联一个文件，这里是网络套接字。
* close会关闭用户应用程序中的socket句柄，释放相关资源，从而触发关闭TCP连接
* 关闭TCP连接，是关闭网络套接字，断开连接
* close只是减少引用计数，只有当引用计数为0的时候，才发送fin，真正关闭连接
* shutdown不同，只要以SHUT_WR/SHUT_RDWR方式调用即发送FIN包
* shutdown后要调用close
* 保持连接的某一端想关闭连接了，但它**需要确保要发送的数据全部发送完毕以后才断开连接**，此种情况下需要使用优雅关闭，一种是shutdown，一种是设置SO_LINGER的close
* 半关闭，是关闭写端，但可以读对方的数据，这种只能通过shutdown实现

### close

close函数会关闭文件描述符，不会立马关闭网络套接字，除非引用计数为0，则会触发调用关闭TCP连接。

* 检查接收缓冲区是否有数据未读(不包括FIN包)，如果有数据未读，协议栈会发送RST包，而不是FIN包。如果套接字设置了SO_LINGER选项，并且lingertime设置为0，这种情况下也会发送RST包来终止连接。其他情况下，会检查套接字的状态，只有在套接字的状态是TCP_ESTABLISHED、TCP_SYN_RECV和TCP_CLOSE_WAIT的状态下，才会发送FIN包
* 若有多个进程调用同一个网络套接字，会将网络套接字的文件描述符+1，close调用只是将当前套接字的文件描述符-1，只会对当前的进程有效，只会关闭当前进程的文件描述符，其他进程同样可以访问该套接字
* close函数的默认行为是，关闭一个socket，close将立即返回，TCP模块尝试把该socket对应的TCP缓冲区中的残留数据发送给对方，并不保证能到达对方
* close行为可以通过SO_LINGER修改

```C++
struct linger{
    int l_onoff;    //开启或关闭该选项
    int l_linger;   //滞留时间
}
```

* l_onoff为0，该选项不起作用，采用默认close行为
* l_onoff不为0
  * l_linger为0，close立即返回，TCP模块丢弃被关闭的socket对应的TCP缓冲区中的数据，给对方发送RST复位信号，这样可以异常终止连接，且完全消除了TIME_WAIT状态
  * l_linger不为0
    * 阻塞socket，被关闭的socket对应TCP缓冲区，若还有数据，close会阻塞，进程睡眠，直到收到对方的确认或等待l_linger时间，若超时仍未收到确认，则close返回-1设置errno为EWOULDBLOCK
    * 非阻塞socket，close立即返回，需要根据返回值和errno判断残留数据是够发送完毕

### shutdown

shutdown没有采用引用计数的机制，会影响所有进程的网络套接字，可以只关闭套接字的读端或写端，也可全部关闭，用于实现半关闭，会直接发送FIN包

* SHUT_RD，关闭sockfd上的读端，不能再对sockfd文件描述符进行读操作，且接收缓冲区中的所有数据都会丢弃
* SHUT_WR，关闭写端，确保发送缓冲区中的数据会在真正关闭连接之前会发送出去，不能对其进行写操作，连接处于半关闭状态
* SHUT_RDWR，同时关闭sockfd的读写

## 解决TCP粘包

### 什么是TCP粘包

由于TCP是流协议，因此TCP接收不能确保每次一个包，有可能接收一个包和下一个包的一部分。

### 如何解决

包头和包体，包头中有包体长度

## select可以直接判断网络断开吗

不可以。若网络断开，select检测描述符会发生读事件，这时调用read函数发现读到的数据长度为0.

## send和recv的阻塞和非阻塞情况

send函数返回100，并不是将100个字节的数据发送到网络上或对端，而是发送到了协议栈的写缓冲区，至于什么时候发送，由协议栈决定。

### send

* 阻塞
  * 一直等待，直到写缓冲区有空闲
    * 成功写返回发送数据长度
    * 失败返回-1
* 非阻塞
  * 不等待，立即返回，成功返回数据长度
  * 返回-1，判断错误码
    * 若错误码为EAGAIN或EWOULDBLOCK则表示写缓冲区不空闲
    * 若错误码为ERROR，则表示失败

### recv

* 阻塞
  * 一直等待，直到读缓冲区有数据
    * 成功写返回数据长度
    * 失败返回-1
* 非阻塞
  * 不等待，立即返回，成功返回数据长度
  * 返回-1，判断错误码
    * 若错误码为EAGAIN或EWOULDBLOCK则表示读缓冲区没数据
    * 若错误码为ERROR，则表示失败
  * 返回0
    * 对端关闭连接

## 网络字节序和主机序

字节序分为大端字节序和小端字节序，大端字节序也称网络字节序，小端字节序也称为主机字节序。

* 大端字节序
  * 一个整数的高位字节存储在低位地址，低位字节存储在高位地址
* 小端字节序
  * 高位字节存储在高位地址，低位字节存储在低位地址
* 转换API
  * htonl 主机序转网络序，长整型，用于转换IP地址
  * htons 主机序转网络序，短整型，用于转换端口号
  * ntohl 网络序转主机序
  * ntohs 网络序转主机序

## [IP地址分类及转换](https://blog.csdn.net/kzadmxz/article/details/73658168)

### IP地址分类

### IP转换

字符串表示的点分十进制转换成网络字节序的IP地址

* pton，点分十进制转换成地址
* ntop，地址转换成点分十进制

## [select实现异步connect](https://blog.csdn.net/nphyez/article/details/10268723)

通常阻塞的connect 函数会等待三次握手成功或失败后返回，0成功，-1失败。如果对方未响应，要隔6s，重发尝试，可能要等待75s的尝试并最终返回超时，才得知连接失败。即使是一次尝试成功，也会等待几毫秒到几秒的时间，如果此期间有其他事务要处理，则会白白浪费时间，而用非阻塞的connect 则可以做到并行，提高效率。

### 实现步骤

* 创建socket，返回套接字描述符；
* 调用fcntl 把套接字描述符设置成**非阻塞**；
* 调用connect 开始建立连接；
* 判断连接是否成功建立。

### 判断连接是否成功建立

* 如果为**非阻塞**模式，则调用connect()后函数立即返回，如果连接不能马上建立成功（返回-1），则errno设置为EINPROGRESS，此时TCP三次握手仍在继续。
  * 如果connect 返回0，表示连接成功（服务器和客户端在同一台机器上时就有可能发生这种情况）
  * 失败可以调用select()检测非阻塞connect是否完成。select指定的超时时间可以比connect的超时时间短，因此可以防止连接线程长时间阻塞在connect处。
* 调用select 来等待连接建立成功完成；
  * 如果select 返回0，则表示建立连接超时。我们返回超时错误给用户，同时关闭连接，以防止三路握手操作继续进行下去。
  * 如果select 返回大于0的值，并不是成功建立连接，而是表示套接字描述符可读或可写
    * 当连接建立成功时，套接字描述符变成可写（连接建立时，写缓冲区空闲，所以可写）
    * 当连接建立出错时，套接字描述符变成既可读又可写（由于有未决的错误，从而可读又可写）
  * 如果套接口描述符可写，则我们可以通过调用getsockopt来得到套接口上待处理的错误（SO_ERROR）
    * 如果连接建立成功，这个错误值将是0
    * 如果建立连接时遇到错误，则这个值是连接错误所对应的errno值（比如：ECONNREFUSED,ETIMEDOUT等）。

## 为什么忽略SIGPIPE信号

* 假设server和client 已经建立了连接，server调用了close, 发送FIN 段给client（其实不一定会发送FIN段，后面再说），此时server不能再通过socket发送和接收数据，此时client调用read，如果接收到FIN 段会返回0
* 但client此时还是可以write 给server的，write调用只负责把数据交给TCP发送缓冲区就可以成功返回了，所以不会出错，而server收到数据后应答一个RST段，表示服务器已经不能接收数据，连接重置，client收到RST段后无法立刻通知应用层，只把这个状态保存在TCP协议层。
* 如果client再次调用write发数据给server，由于TCP协议层已经处于RST状态了，因此不会将数据发出，而是发一个SIGPIPE信号给应用层，SIGPIPE信号的缺省处理动作是终止程序。

* 有时候代码中需要连续多次调用write，可能还来不及调用read得知对方已关闭了连接就被SIGPIPE信号终止掉了，这就需要在初始化时调用sigaction处理SIGPIPE信号，对于这个信号的处理我们通常忽略即可

* 往一个读端关闭的管道或者读端关闭的socket连接中写入数据，会引发SIGPIPE信号。当系统受到该信号会结束进程是，但我们不希望因为错误的写操作导致程序退出。

* 通过sigaction函数设置信号，将handler设置为SIG_IGN将其忽略
* 通过send函数的MSG_NOSIGNAL来禁止写操作触发SIGPIPE信号

## 如何设置文件描述符非阻塞

* 通过fcntl设置

```c++
int flag = fcntl(fd, F_GETFL);
flag |= O_NONBLOCK;
fctncl(fd, F_SETFL, flag);
```

---

## Linux系统编程及基本知识

# linux系统编程及基本命令

## 系统编程
>
> * [按下开机键Linux发生了什么](#按下开机键Linux发生了什么)
> * [进程退出方式及区别](#进程退出方式及区别)
> * [回收进程资源的方式和区别](#回收进程资源的方式和区别)
> * [守护进程](#守护进程)
> * [线程退出方式与线程回收](#线程退出方式与线程回收)
> * [共享内存](#共享内存)
> * [信号量](#进程中的信号量)
> * [信号通知进程](#信号通知进程)
> * [valgrind检查内存泄漏](#valgrind检查内存泄漏)
> * [程序从main函数开始吗](#程序从main函数开始吗)

## 基本命令
>
> * [Linux基本目录结构](#Linux基本目录结构)
> * [文件操作命令](#文件操作命令)
> * [磁盘及内存命令](#磁盘及内存命令)
> * [进程命令](#进程命令)
> * [网络命令](#网络命令)
> * [字符处理命令](#字符处理命令)
> * [调试命令](#调试命令)
> * [文本处理工具](#文本处理工具)

## [按下开机键Linux发生了什么](https://blog.csdn.net/T146lLa128XX0x/article/details/93988210)

BIOS -> MBR -> 引导加载程序 -> 内核 -> init process -> login

## [进程退出方式及区别](https://www.cnblogs.com/xiaojianliu/p/8473083.html)

不管哪种退出方式，系统最终都会执行内核的同一代码，这段代码用来关闭进程打开的文件描述符，释放它占用的内存和其他资源

* 退出
  * 正常退出
    * main函数调用return
    * 调用exit()函数
    * 调用_exit()函数
  * 异常退出
    * 调用abort函数
    * 进程收到某个信号，该信号使程序终止

* 已结束进程的状态
  * shell执行 echo $?，保存最近一次运行的进程的返回值
    * 程序中main函数运行结束，保存main函数的返回值
    * 程序调用exit函数结束运行，保存exit函数的参数
    * 程序异常退出，保存异常出错的错误号

* 区别
  * exit和return的区别
    * exit是函数，有参数，exit执行完会把控制权交给系统，exit(0)表示正常终止，其他值表示有错误发生
    * return是函数执行完后的返回，return执行完后把控制权交给调用函数
  * exit和abort的区别
    * exit是正常终止进程
    * abort是异常终止进程
  * exit和_exit函数的区别
    * exit在头文件stdlib.h中声明，_exit是在头文件unistd.h中声明
    * exit是_exit之上的一个封装， **exit先刷新流数据** ，再调用_exit函数
      * _exit会关闭进程打开的文件描述符，清理内存，不会刷新流数据
      * linux的库函数，有一种“缓冲IO”的操作，对应每一个打开的文件，在内存中有一片缓冲区，每次读文件，会连续读出若干条记录，下次再读文件的时候，直接从内存的缓冲区中读；同样写文件也是先写入缓冲区，满足一定条件才将缓冲区的内容一次性写入文件。具体可以看printf和write的区别，及行缓冲和全缓冲
      * exit先刷新流数据，将文件缓冲区的内容写回文件，可以保证数据的完整性，_exit会将数据直接丢失

## 回收进程资源的方式和区别

* init进程（进程号为1）会周期性的调用wait系统调用来清除各个僵尸进程
* wait
  * `pid_t wait (int *status)` status表示子进程的退出状态，成功返回值为子进程进程号，失败为-1
  * 进程一旦调用wait函数，立即阻塞自己， 判断当前进程的某个子进程是否变成僵尸进程
    * 若存在则收集子进程的信息，将它彻底销毁然后返回
    * 若没有，则会一直阻塞，直到出现一个
* waitpid
  * waitpid相当于wait函数的封装，多了两个由用户控制的参数pid和options，可以自定义回收的子进程进程号，并设置是否阻塞
  * `pid_t waitpid(pid_t pid, int * status, int options)`
  * pid
    * pid < -1，等待进程组ID为pid绝对值的任何子进程
    * pid = -1，等待任何子进程，相当于wait
    * pid = 0，等待进程组ID与目前进程相同的任何子进程
    * pid > 0，等待子进程ID为pid的进程
  * options
    * 0，与wait相同，也会阻塞
    * WNOHANG，不会阻塞，如果当前没有可回收的子进程，立即返回0

## 守护进程

Daemon进程，守护进程，是脱离终端并在后台运行的进程，脱离终端是为了避免进程运行过程中的信息显示在任何终端上，另外进程越不会被任何终端产生的终端信息所打断。

### 终端，进程组，会话期,setsid函数

* 终端
  * linux中，每一个系统与用户进行交流的界面称为终端。
  * 每一个从此终端开始运行的进程都依附于此终端，这个终端称为这些进程的控制终端，当控制终端被关闭时，相应的进程会自动关闭。
  * 守护进程可以突破这种限制，从运行开始执行，整个系统关闭才退出

* 进程组
  * 进程组是一个或多个进程的集合
  * 进程组由进程组ID唯一标识，该进程组中的进程除了进程号之外，还有进程组ID的属性
  * 进程组中第一个进程默认为进程组长，其进程号 = 进程组ID

* 会话期
  * 会话期是一个或多个进程组的集合
  * 进程组的组长不能创建会话，只有组员才能创建会话，因此都是子进程创建会话实现守护进程
  * 一个会话期开始于用户登录，终止于用户退出，在此期间该用户运行的所有进程都属于这个会话期

* setsid函数
  * 用于创建新会话，将调用setsid的进程担任会话期的会长
  * 让进程摆脱原会话的控制
  * 让进程摆脱原进程组的控制
  * 让进程摆脱原控制终端的控制

* 为什么创建守护进程要调用setsid？
  * 一般子进程实现守护进程，子进程fork于父进程，子进程全盘拷贝了父进程的会话期、进程组、控制终端
  * 虽然父进程退出了，但子进程的各个属性都没变，不算真正意义的独立

### 创建守护进程

* 创建子进程，父进程退出
* 子进程中调用setsid创建新会话
* 切换工作目录，一般切换为根目录/
  * 从父进程继承来的工作目录可能是一个挂载的文件系统，若不修改工作目录，该文件系统不能卸载
* 重设文件权限掩码
  * 由于从父进程继承来的文件权限掩码会屏蔽掉文件权限中的对应位，这给该子进程使用文件带来麻烦
  * 通过umask(0),表示用户、用户组和其他用户都有可读可写可执行权限
* 关闭文件描述符
  * 子进程会从父进程继承一些打开的文件描述符，但这些可能永远不会被守护进程使用，但他们一样消耗系统资源，而且会导致所在文件系统无法结束
  * 守护进程已经脱离了所属的控制终端，因此终端的输入，输出和报错也失去了存在的价值
  * 可以遍历MAXFILE，然后close所有文件描述符
* 如果想结束守护进程，直接kill -9 pid即可

## 线程退出方式与线程回收

### 线程退出方式

注意：不能使用exit，exit表示退出整个进程

* pthread_exit
  * `int pthread_exit(void *retval);`
  * 在任何线程中使用，使该线程直接退出
  * 主线程退出而不影响其他线程，只能使用这种方式
* return
  * 子线程中可以使用，主线程不能使用，主线程代表退出整个进程

### 线程回收

* pthread_join
  * `int pthread_join(pthread_t thread, void **retval)`
  * 用来等待一个线程的结束，并回收该线程的资源
  * 一般是主线程调用，用来等待子线程退出，是阻塞的

### 线程分离

* pthread_detach
  * `int pthread_detach(pthread_t thread)`
  * 分离已经创建的线程，将主线程与子线程分离，子线程结束后，资源自动回收。
  * 状态分离后，该线程的结束状态不能被该进程中的其他线程得到，因此pthread_join不能调用，否则会出错

## [共享内存](https://blog.csdn.net/hj605635529/article/details/73163513)

共享内存有两种shm和mmap

* IPC通信System V版本的共享内存shm
* 存储映射I/O（mmap函数）

### shm

* 原理
  * 多个进程的地址空间映射到同一个物理内存，不同进程可以将同一段共享的内存连接到自己的地址空间中，从而所有进程都可以访问共享内存中的地址
* API
  * `int shmget(key_t key, size_t size, int shmflg);`
    * 在物理内存创建一个共享内存，返回共享内存的编号
    * key是一个非0整数，命名共享内存段，运行成功返回一个与key相关的共享内存标识符
    * size表示以字节为单位指定需要的共享内存的容量
    * shmflag是权限标志位，与open的mode参数一致，若key标识的共享内存不存在，通过0666|IPC_CREAT来创建，并设置权限

  * `void *shmat(int shmid, const void shmaddr,int shmflg);`
    * 连接成功后把共享内存区对象映射到调用进程的地址空间，函数返回各个进程挂接的虚拟的地址空间
    * shmid是挂接的进程号，
    * shmaddr置为NULL，让系统选择一个合适的地址空间进行挂接
    * shmflg表示什么方式进行挂接，一般都是取0.

  * `void *shmdt(const void* shmaddr);`
    * 将共享内存从当前进程中分离，断开用户级页表到共享内存的那根箭头。

  * `int shmctl(int shmid, int cmd, struct shmid_ds* buf);`
    * 释放物理内存中的那块共享内存
    * cmd取IPC_RMID表示删除这块共享内存

### mmap

* 原理
  * mmap是映射磁盘上的一个文件，每个进程在自己的逻辑地址空间中开辟一块空间对磁盘上的文件进行映射
  * 内存映射的过程中，并没有实际的数据拷贝，文件没有被载入内存
  * mmap返回一个指针ptr，它指向进程逻辑地址空间中的一个地址，通过ptr就能够操作文件。但是ptr所指向的是一个逻辑地址，要操作其中的数据，必须通过MMU将逻辑地址转换成物理地址，建立内存映射并没有实际拷贝数据，这时，将产生一个缺页中断，会通过mmap()建立的映射关系，从硬盘上将文件读取到物理内存中

* 效率
  * read()是系统调用，其中进行了数据拷贝，它首先将文件内容从硬盘拷贝到内核空间的一个缓冲区，然后再将这些数据拷贝到用户空间，在这个过程中，实际上完成了两次数据拷贝
  * mmap()也是系统调用，mmap()中没有进行数据拷贝，真正的数据拷贝是在缺页中断处理时进行的，由于mmap()将文件直接映射到用户空间，所以中断处理函数根据这个映射关系，直接将文件从硬盘拷贝到用户空间，只进行了一次数据拷贝

* 映射文件
  * 普通文件
    * open系统调用打开一个文件，然后进行mmap操作，得到共享内存，这种方式适用于任何进程之间。
  * 匿名映射
    * 调用 mmap 时，在参数 flags 中指定 MAP_ANONYMOUS 标志位，并且将参数 fd 指定为 -1 ,用于父子进程之间

### 不同进程访问共享内存

* shm
  * 不同进程通过shmget->shmat函数，将共享内存连接到自己的虚拟内存地址
* mmap
  * 不同进程通过mmap函数创建映射区，将自己的内存虚拟地址映射到磁盘的文件上

### 程序异常退出，共享内存会释放吗？

* 不会
  * Linux中通过API函数shmget创建的共享内存一般都是在程序中使用shmctl来释放的，但是有时为了调试程序，开发人员可能通过Ctrl + C等方式发送中断信号来结束程序，此时程序申请的共享内存就不能得到释放，当然如果程序没有改动的话，重新运行程序时仍然会使用上次申请的共享内存，但是如果我们修改了程序，由于共享内存的大小不一致等原因会导致程序申请共享内存错误。
* 如何释放
  * 如果总是通过Crtl+C来结束的话，可以做一个信号处理器，当接收到这个信号的时候，先释放共享内存，然后退出程序。
  * 不管你以什么方式结束程序，如果共享内存还是得不到释放，那么可以通过linux命令ipcrm shm shmid来释放，在使用该命令之前可以通过ipcs -m命令来查看共享内存。

### 两者的区别

* 作用
  * mmap系统调用并不完全是为了共享内存来设计的，它本身提供了不同于一般对普通文件的访问的方式，进程可以像读写内存一样对普通文件进行操作
  * IPC的共享内存shm是纯粹为了共享。
* 映射位置
  * mmap是在磁盘上建立一个文件，每个进程地址空间中开辟出一块空间对磁盘上的文件进行映射。
  * shm每个进程映射到同一块物理内存，shm保存在物理内存，这样读写的速度要比磁盘要快，但是存储量不是特别大
* 内容丢失
  * 进程挂了重启不丢失内容，二者都可以做到
  * 机器挂了重启，mmap把文件存在磁盘上，可以不丢失内容（文件内保存了OS同步过的映像），而 shmget 会丢失

## [信号量](https://blog.csdn.net/qq_38813056/article/details/85706006)

[参考资料](https://blog.csdn.net/mijichui2153/article/details/84930553)
信号量广泛用于进程或线程间的同步和互斥，信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问，分为两种POSIX信号量和SystemV信号量

### POSIX信号量

* 有名信号量，用于进程间同步
* 无名信号量，用于线程间同步
  * posix信号量一般是单个计量信号，全程操作一个信号量

### SystemV信号量，用于进程间同步

* 进程中使用共享内存实现进程间通信，但他并不是线程安全的，需要通过信号量进行同步
* 一般说的systemV信号量是计量信号集，可以使用多个信号量进行同步

* API
  * `int semget(key_t key, int nsems, int semflag);`

## [信号通知进程](http://www.360doc.com/content/16/0804/10/30953065_580685165.shtml)

### 信号的使用

用kill函数发送信号，在接收进程里，通过signal或者signalaction函数调用sighandler，来启动对应的函数处理信号消息。

* 发送信号
  * raise，向本身发送信号
  * kill，向指定进程发送信号
    * pid > 0 ：向进程号为pid的进程发送信号
    * pid = 0 ：向当前进程所在的进程组发送信号
    * pid = -1 ：向所有进程(除PID=1外)发送信号(权限范围内)
    * pid < -1 ：向进程组号为-pid的所有进程发送信号
* 自定义信号动作/注册捕捉函数
  * signal
    * `typedef void (*sighandler_t)(int);`
    * `sighandler_t signal(int signum, sighandler_t handler);`
    * signal里面需要设置捕捉的信号signum、自定义回调函数handler
  * sigaction
    * 同样需要设置捕捉信号和回调处理函数

### 信号处理机制

每个进程之中，都有存着一个表，里面存着每种信号所代表的含义，内核通过设置表项中每一个位来

* 信号的接收
  * 接收信号的任务是由内核代理的，当内核接收到信号后，会将其放到对应进程的信号队列中，同时向进程发送一个中断，使其陷入内核态。注意，此时信号还只是在队列中，对进程来说暂时是不知道有信号到来的。

* 信号的检测
  * 进程陷入内核态后，有两种场景会对信号进行检测：
    * 进程从内核态返回到用户态前进行信号检测
    * 进程在内核态中，从睡眠状态被唤醒的时候进行信号检测
  * 当发现有新信号时，便会进入下一步，信号的处理。

* 信号的处理
  * ( **内核** )信号处理函数是运行在用户态的，调用处理函数前，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。
  * ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。
  * ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
  * ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。

至此，一个完整的信号处理流程便结束了，如果同时有多个信号到达，上面的处理流程会在第2步和第3步骤间重复进行。

### 信号通知进程，为什么通过内核转发？

* 之所以要通过内核来转发，这样做的目的应该也是为了对进程的管理和安全因素考虑。
* 因为在这些信号当中，SIGSTOP和SIGKILL这两个信号是可以将接收此信号的进程停掉的，而这类信号，肯定是需要有权限才可以发出的，不能够随便哪个程序都可以随便停掉别的进程。

### 信号处理示例

* A，B两个进程，A进程发送信号给B进程，信号并不是直接从进程A发送给进程B，而是要通过内核来进行转发。
* A进程发送的信号消息，由内核对B进程相应的表项进行设置。
  * 内核接受到这个信号消息后，会先检查A进程是否有权限对B进程的信号表对应的项进行设置
    * 如果可以，就会对B进程的信号表进行设置
    * 如果不可以，就忽略
    * 信号处理有个特点，就是没有排队的机制，也就是说某个信号被设置之后，如果B进程还没有来及进行响应，那么如果后续第二个同样的信号消息过来，就会被阻塞掉，也就是丢弃。
  * 内核对B进程信号设置完成后，就会发送中断请求给B进程，这样B进程就进入到内核态
  * 进程B根据那个信号表，查找对应的此信号的处理函数，保护现场，跳回到用户态执行信号处理函数，处理完成后，再次返回到内核态，再次保护现场，然后再次返回用户态，从中断位置开始继续执行。
  * 保护现场是在用户态和内核态之间跳转的时候，对堆栈现场的压栈保存。

## valgrind检查内存泄漏

* 检查内存泄露原理
  * 检测内存泄漏的关键是要能截获住对分配内存和释放内存的函数的调用。
  * 截获住这两个函数，我们就能跟踪每一块内存的生命周期，比如，每当成功的分配一块内存后，就把它的指针加入一个全局的list中；每当释放一块内存，再把它的指针从list中删除。这样，当程序结束的时候，list中剩余的指针就是指向那些没有被释放的内存
* 最常用的是memcheck，用于发现绝大多数的内存错误使用情况
  * 使用未初始化的内存
  * 使用已经释放的内存
  * 内存访问越界
* memcheck原理
  * Memcheck 能够检测出内存问题，关键在于其建立了两个全局表。
    * Valid-Value 表：对于进程的整个地址空间中的每一个字节(byte)，都有与之对应的 8 个 bits；对于 CPU 的每个寄存器，也有一个与之对应的 bit 向量。这些 bits 负责记录该字节或者寄存器值是否具有有效的、已初始化的值。
    * Valid-Address 表：对于进程整个地址空间中的每一个字节(byte)，还有与之对应的 1 个 bit，负责记录该地址是否能够被读写。
  * 检测原理：
    * 当要读写内存中某个字节时，首先检查这个字节对应的 A bit。如果该A bit显示该位置是无效位置，**memcheck则报告读写错误**。
    * 内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节对应的 V bit 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 memcheck 会检查对应的V bits，如果该值尚未初始化，则会**报告使用未初始化内存错误**。

## 程序从main函数开始吗

* 程序在main函数开始之前，已经完成了全局变量的初始化，堆栈初始化和系统I/O
* main之前完成全局变量的构造，在main之后完成全局变量的析构
* 另外atexit函数还可以在main函数之后运行，它接受一个函数指针作为参数

## Linux基本目录结构

* /bin，binaries存放二进制可执行文件
* /usr，unix shared resources用于存放共享的系统资源
* /sbin，super user binaries存放二进制可执行文件，只有root才能访问
* /etc，etcetera存放系统的配置文件
* /boot，存放启动linux和引导文件的目录
* /lib，存放着系统最基本的动态连接共享库
* /dev，存放linux的设备文件，比如显示器，键盘等
* /mnt，用户可以在这个目录下挂在其他临时文件系统
* /media，linux系统会自动识别一些设备，例如U盘、光驱等等，linux会把识别的设备挂载到这个目录下
* [/proc](https://www.cnblogs.com/zydev/p/8728992.html)，proc被称为虚拟文件系统，它是一个控制中心，可以通过更改其中某些文件改变内核运行状态，它也是内核提空给我们的查询中心，用户可以通过它查看系统硬件及当前运行的进程信息。
  * /proc/loadavg，前三列分别保存最近1分钟，5分钟，及15分钟的平均负载。
  * /proc/meminfo，当前内存使用信息
  * /proc/cpuinfo ，       CPU的详细信息
  * /proc/diskstats，    磁盘I/O统计信息列表
  * /proc/net/dev  ，    网络流入流出统计信息
  * /proc/filesystems，  支持的文件系统
  * /proc/cmdline ，     启动时传递至内核的启动参数，通常由grub进行传递
  * /proc/mounts ，    系统当前挂在的文件系统
  * /proc/uptime ，   系统运行时间
  * /poc/version ，    当前运行的内核版本号等信息
* /opt，这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。

## 文件操作命令

* ls
  * `ls -lrt` 递归显示文件的详细信息并按照时间排序
* tail
  * `tail -n 100` 显示文件尾，指定显示行数，默认10行
* chmod
  * `chmod 777 filename` 修改文件的权限为用户，用户组，其他人有所有权限
* rm
  * `rm -r` 递归删除子目录
  * `rm -f` 强制删除
* vim的三种模式
  * 命令模式(一般模式，通过yy进行赋值)
  * 编辑模式，通过i或者a
  * 末行模式，冒号

## 磁盘及内存命令

* 文件大小和占用空间大小是不一样的，因为要对齐

* 显示每个文件和目录的磁盘使用空间
  * `(disk used) du -h`
* 显示磁盘分区上可以使用的磁盘空间
  * `(disk free) df -h`
* 显示内存使用情况
  * [free](https://www.cnblogs.com/ultranms/p/9254160.html)
  * Mem是物理内存的使用情况
  * Swap是交换空间的使用情况
  * total是物理内存和交换空间的总大小
  * used是物理内存和交换空间已经被使用的大小
  * free是物理内存和交换空间可用空间（从内核和系统的角度看，真正尚未被使用的物理内存数量）
  * shared 列显示被共享使用的物理内存大小。
  * buff/cache 列显示被 buffer 和 cache 使用的物理内存大小（其实是内存为缓存磁盘数据设置的缓冲区）。
  * available 列显示还可以被应用程序使用的物理内存大小，当应用程序需要内存时，如果没有足够的 free 内存可以用，内核就会从 buffer 和 cache 中回收内存来满足应用程序的请求，理想来说available  = free + buffer + cache
 
## 进程命令

* ps
  * 当前运行的进程的快照，指定ps命令的那个时刻的那些进程
  * `ps -aux` 查看所有的在内存中的进程信息
  * `ps -ajx` 查看进程组相关信息，可以追踪进程之间的血缘关系
  * `ps -ef` 线城市所有进程信息，并显示程序间的关系
  * `ps -u username` 显示指定用户username信息
* top
  * 实时显示系统中各个进程的资源占用情况，按"q"退出top命令
  * `top -H -p pid`显示对应pid的所有线程资源使用情况
  * `load average` 表示系统最近1min,5min,15min的平均负载，越大表示负载越来越小
  * %MEM物理内存占用比
  * Cpu(s)和%cpu
    * Cpu(s)表示的是所有用户进程占用整个cpu的平均值
    * %CPU显示的是进程占用一个核的百分比，而不是整个cpu（8核）的百分比，有时候可能大于100，那是因为该进程启用了多线程占用了多个核心，所以有时候我们看该值得时候会超过100%，但不会超过总核数*100。
* kill
  * 杀掉进程
  * `kill -9 pid`杀掉指定进程
* lsof
  * 列出当前系统打开文件的工具
  * `lsof -i :8600` 查看8600端口的运行情况
  * `lsof -u username` 查看username打开的文件
  * `lsof -c string` 查看包含指定字符的进程所打开的文件

## 网络命令

* netstat
  * 用于显示与IP、TCP、UDP、和ICMP协议相关的统计数据，用于检验本机各端口的网络连接情况
  * `-a` 列出所有端口
  * `-p` 显示出进程和PID
  * `-n` 将主机、端口和用户名用数字代替
  * `netstat -apn | grep port` 显示指定端口的状态信息和进程信息
* tcpdump
  * `tcpdump host ip` 截获主机发出和收到的数据包
  * `tcpdump port 6666` 截获端口上通过的包
  * `tcpdump -i eth0` 截获某网卡上的包
* ping
  * `ping ip` 用于测试另一台主机是否可达，测试网络是否连通以及时延
  * windows下ping是32比特，默认发送4次数据包结束
  * linux下ping是64比特，默认不停发送数据包，直到手动停止
* host
  * `host 域名` 返回域名的IP地址
  * 用来查询DNS记录
* ifconfig
  * 输出当前系统中所有处于活动状态的网络接口
  * `ifconfig eth0 ip/24` 手工指定网卡的IP地址和广播地址，其中广播地址可以根据掩码计算出来
  * `ifconfig eth0 up` 启动网卡eht0
  * `ifconfig eth0 down` 关闭网卡eht0
* traceroute

## 字符处理命令

* 管道|
* grep

## 调试命令

* gdb
  * `l` 列出函数代码及行数
  * `b 16` 在16行设置断点
  * `b func` 在函数func设置断点
  * `r` 运行程序
  * `n` 单条执行程序
  * `p i` 打印i变量的值
  * `bt` 查看函数堆栈
  * `finish` 退出函数
  * `q` 结束调试
* strace
  * 监控用户空间进程和内核的交互，跟踪系统调用和信号传递
  * `strace -c ./test` 统计./test使用的系统调用
  * `strace -p pid` 跟踪现有进程
* ipcs
  * 用于报告系统的消息队列，信号量和共享内存等使用情况
  * `ipcs -a`用于列出本用户所有相关的ipcs参数
  * `ipcs -q`用于列出进程中的消息队列
  * `ipcs -s`用于列出所有的信号量
  * `ipcs -m`用于列出所有的共享内存信息
  * `ipcs -l`用于列出系统限额，比如共享内存最大限制
  * `ipcs -u`用于列出当前的使用情况
* ipcrm
  * 用于移除一个消息队列，或者共享内存段，或者一个信号集，同时会将与ipc对象相关联的数据也一起移除，只有超级管理员，或者ipc对象的创建者才能这样做
  * `ipcrm -M shmkey`  移除用shmkey创建的共享内存段
  * `ipcrm -m shmid`    移除用shmid标识的共享内存段
  * `ipcrm -Q msgkey`  移除用msqkey创建的消息队列
  * `ipcrm -q msqid`  移除用msqid标识的消息队列
  * `ipcrm -S semkey`  移除用semkey创建的信号
  * `ipcrm -s semid`  移除用semid标识的信号

## 文本处理工具

* sed
* awk

***

# 项目
